<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux命令ulimit]]></title>
    <url>%2F2019%2F09%2F17%2FLinux%E5%91%BD%E4%BB%A4ulimit%2F</url>
    <content type="text"><![CDATA[Linux中，ulimit用来限制当前用户可使用的各种系统资源，在开发中了解ulimit的内容还是相当重要的，这里就简单整理总结一下。 ulimit用法1ulimit [-SHcdefilmnpqrstuvx] [limit] 我们经常还会用到开放所有限制来调试：1ulimit unlimited 所有资源限制类型用ulimit查看当前所有资源1234567891011121314151617&gt; ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 15065max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 15065virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 这样就显示了所有可以分配的资源，以下是逐个解释： core file size: 程序发生错误时会生成coredump文件以用来排除错误，这里用来限制coredump文件的大小；默认为0，所以默认情况下不生成coredump文件；这个选项非常重要，因为在prod环境部署的项目一定要开启这个限制，否则无法排除某些特殊的错误。 data seg size: 每个进程数据段的最大值；数据段是用来初始化全局变量的一块区域，属于静态内存分配。 scheduling priority: 进程优先级NICE值限制；改设置只对普通用户有效，限制普通用户进程可以设置的优先级范围。 file size: 可创建最大文件大小。 pending signals: 表示可以被挂起/阻塞的最大信号数量； max locked memory: 内存锁定值的限制；内存中的内容不不是一直在内存中的，有的时候再交换区或者磁盘上，所以有些时候我们希望有些数据只存在于内存里而不会转移到交换区或者磁盘；这里限制的是可以锁定到内存的数据的大小； max memory size: 最大内存限制；字面意思；但是在很多系统里没有作用； open files: 每个进程可以打开的文件数量； pipe size: 管道缓存；但是不能改变，只能是8 * 512(bytes)； POSIX message queues: 可以创建使用POSIX消息队列的最大值； real-time priority: 限制程序实施优先级的范围； stack size: 堆栈的最大值； cpu time: 每个进程可以使用CPU的最大时间; max user processes: 每个用户运行的最大进程并发数; virtual memory: 可使用的最大虚拟内存; file locks: 文件锁的限制;只在2.4内核之前有用; 软限制和硬限制1.ulimit中有-S 和 -H 两个标记用来区分软限制和硬限制，无论是查看还是修改比如要设置创建文件的大小的软上限，不指定SH的时候，同时设定软上限和硬上限；1ulimit -f 100 然后我们用SH分别查看，可以看到软硬上限被同时设置了1234$ ulimit -Sf100$ ulimit -Hf100 2.软限制不能超过硬限制，硬限制也不能小于软限制接着刚才，如果我们单独设置软上限超过硬上限或者硬上限小于软上限，就会报错：1234$ ulimit -Sf 200-bash: ulimit: file size: 无法修改 limit 值: 无效的参数$ ulimit -Hf 10-bash: ulimit: file size: 无法修改 limit 值: 无效的参数 3.普通用户只能缩小硬限制，超级用户可以扩大硬限制普通用户缩小硬限制：12ulimit -Hf 50-bash: ulimit: file size: 无法修改 limit 值: 无效的参数 4.硬限制的作用是控制软限制，软限制的作用是限制实际用户的使用ulimit设置永久生效上面的命令只能临时修改ulimit的限制，修改修改/etc/security/limits.conf可以使设置永久生效。打开该文件有注释，注释的内容就是如何编写设置，比如我们要root用户文件大小限制都设置成4096，那么就在这个文件最下面添加以下内容：12root soft fsize 4096root hard fsize 4096 下次登录时查看，就已经生效了：12$ ulimit -f10000]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis五种数据结构应用场景]]></title>
    <url>%2F2019%2F08%2F19%2FRedis%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[Redis有五种数据结构，分别是: String/Hash/List/Set/Zset；使用这五种数据结构就能够完成很多应用，所以有必要简单总结一下，作为解决问题的一个索引。 字符串 StringString是最常用的数据类型，常用命令有以下这些：set get del mset mget incr decr incrbyfloat append strlen setrange getrange；在使用redis的各种命令时，除了关注用法以外还需要注意的就是时间复杂度，这些再redis官网都可以找到，我就不再赘述了；redis命令文档：https://redis.io/commands；set是设置键，是最常用的，有几个选项： ex设置秒级过期时间 px毫秒级过期时间 nx键必须不存在，用于添加 xx键必须存在，用于更新 另有setnx和setex代替nx和ex两个参数。set可以设置过期时间是redis可以作为缓存使用的最重要的特性；mset和mget用于批量设置值和获取值；网络是Redis的瓶颈，需要尽量减少网络的访问次数；字符串有以下几个典型应用场景：缓存功能 最常用的功能，将热数据的查询结果缓存到redis；计数 也是减少数据库压力的方法之一，比如文章的点击量再一分钟内在redis中自增，每分钟写一次Mysql，清空redis；共享session 这个在分布式或者负载均衡的web服务中非常常用，用户被负载均衡到不同服务器上的时候并不希望session丢失而重新登录；可以用redis做一个session管理的服务；同时还可以规定用户需要重新登录的时间间隔；限速 比如短信接口，我们不希望用户能无限访问，可以用string可以设置过期时间的特性；类似其他ip访问限制也同理 哈希 HashHash我觉得是最不常用的，简单了解一下，常用命令有这些：hset hget hdel hlen hmget hmset hexists hkeys hvals hgetall hincrby hstrlen；Hash的典型使用场景：比如我们想缓存用户数据，可以将数据库中的用户数据的每一列在哈希结构里表示出来，更新较为灵活；但是，好像没太大用，因为用string也可以，只不过节约了一些内存。哈希的应用不算丰富。 列表 ListList由于特性比较丰富，用法也非常多，先来看看常用命令：添加 rpush lpush linsert；查 lrange lindex llen；删除 lpop rpop lrem ltrim；修改 lset；阻塞操作 blpop brpop；列表是有序的，并且在列表的两侧都可以push和pop，因此lpush + lpop就形成了一个栈；lpush + rpop就形成了一个队列；还有一种特殊的pop形式，就是阻塞弹出brpop，这个特殊的弹出其实就是为消息队列而准备的，可以防止一个数据被多次消费；因此lpush+brpop可以作为消息队列；ltrim可以指定索引范围并保留，删除其他元素，因此配合lpush可以作为一个有限集合，比如需求是只想保留100条数据，在第101条插入时删除第一条。 集合 Set集合的特性也比较丰富：集合中不会存在重复元素；集合元素是无序的；集合内可以增删改查；可以取多个集合的交并差集；集合有以下常用命令：sadd srem scarf sismember；srandmember 返回指定个数的元素；spop 随机弹出多个元素；smembers 获取所有元素；sinter 交集；sunion 并集；sdiff 差集；在使用交并差集是，在元素比较多的情况下非常耗时，所以sinter sunion sidff有destination参数，可以将结果保存到新键中；集合的能实现的最贴合的功能可能就是标签了，比如每个用户有不用的兴趣标签，每个标签有不用的用户；使用sinter就可以计算出两个用户兴趣的交集，这在社交软件中非常常用；spop可以从集合中随机弹出元素，srandmember可以随机取出一个元素，但是不删除这个元素，这两个命令都可以实现不用需求的抽奖系统；部分应用中有靓号系统，也可以通过集合实现，可以srandmember多个靓号以供选择，spop删除那个被选中的靓号，sismember确定系统随机生成的数是不是靓号，以免被下发； 有序集合 ZsetZset区别于Set最大的特点是可以给每个元素设置分数，作为排序的依据；这里就有必要整理一下列表、集合、和有序集合的异同点了： 数据结构 是否允许重复元素 是否有序 有序实现方式 应用场景 列表 是 是 索引下标 时间轴 消息队列等 集合 否 否 无 标签 社交等 有序集合 否 是 分值 排行榜 社交 有序集合常用命令如下：zadd nx必须存在用于添加 xx必须不存在 用于更新 ch返回受影响的个数 incr 增加分数zscore 获取分数zcard 获取成员个数zrank 获取排名zrevrank 反向排名 withscore参数可以同时返回分数zrem zincrby zrangebyscore 返回指定范围内的成员zrevrangebyscorezinterscore 这个命令用于取交集，但是参数非常多：destination 交集计算结果保留到这个键；numkeys 需要做交集计算键的个数；key 需要做交集甲酸的键；wieghts 每个键的权重；agreegate sum|min|max 汇总形式；可以参考一下redis的文档更详细了解这个命令；当然还有zunionstore取并集；使用场景就是各种排行榜系统啦：zadd在增加条目的同时可以给条目分配一个分数；zincrby可以增加某个条目的分数；zrank\zrevrank等可以查看排名前几位或者后几位的条目。 总结在使用基本数据结构时，有两个点需要注意：命令的时间复杂度：因为Redis是单线程，时间过长的查询会阻塞其他任务；数据结构的编码：虽然Redis会自动根据情况切换数据编码，但是要优化Redis还是要了解数据编码的形式和设置合理的参数；下面我整理一个表，大致表示一下基本数据结构能实现的功能： 数据结构 命令 功能 String 几乎所有命令 大部分的缓存任务 热数据访问缓存 高频写入缓存 Hash - - List lpush + lpop 栈 List lpush + rpop 队列 List lpush + brpop 消息队列 List lpush + ltrim 有序集合 Set sadd 标签 Set spop/srandmember 抽奖系统 Set sadd + sinter 社交需求 Zset 许多常用命令 排行榜系统]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次Mongodb复杂聚合查询]]></title>
    <url>%2F2019%2F08%2F01%2F%E8%AE%B0%E4%B8%80%E6%AC%A1Mongodb%E5%A4%8D%E6%9D%82%E8%81%9A%E5%90%88%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[今天开发中遇到一个比较复杂的聚合查询，我觉得有必要记录一下；当然不会用项目中的例子，我举个差不多的例子来讲。 学生1,2,3参数可以参加1,2,3三个兴趣小组，每个学生可以参加多个兴趣小组，每个学生参加的兴趣小组有课程时间安排，周一到周五五天的某几天可以参加（1-5表示周一到周五）。于是有了下面这个表，sid表示学生学号，gid表示兴趣小组编号，present表示学生需要出席小组的日期；并且日程安排是新登记到数据库的功能，部分兴趣小组还没有这个字段：1234567891011db.groupstudent.insert([&#123;_id:"1_2", sid: 1, gid:2, present:[2,3,4]&#125;,&#123;_id:"1_3", sid: 1, gid:3, present:[1,4,5]&#125;,&#123;_id:"2_1", sid: 2, gid:1, present:[2,3]&#125;,&#123;_id:"2_2", sid: 2, gid:2, present:[1,4]&#125;,&#123;_id:"3_1", sid: 3, gid:1, present:[4,5]&#125;,&#123;_id:"3_3", sid: 3, gid:3, present:[1,2,3,4]&#125;,&#123;_id:"3_4", sid: 3, gid:4&#125;,&#123;_id:"2_4", sid: 2, gid:4&#125;,]) ok，现在需求来了，我们要通过这张表整理出每个兴趣小组每天应该出席的学生列表，还没登记该功能的小组不统计，要求的最终效果如下：123&#123; "gid" : 1, "presentStudentsOfDays" : &#123; "4" : [ 3 ], "3" : [ 2 ], "5" : [ 3 ], "2" : [ 2 ] &#125; &#125;&#123; "gid" : 2, "presentStudentsOfDays" : &#123; "2" : [ 1 ], "3" : [ 1 ], "4" : [ 2, 1 ], "1" : [ 2 ] &#125; &#125;&#123; "gid" : 3, "presentStudentsOfDays" : &#123; "1" : [ 3, 1 ], "5" : [ 1 ], "4" : [ 3, 1 ], "2" : [ 3 ], "3" : [ 3 ] &#125; &#125; 好了，接下来我们一步步做聚合。 1.筛选出已经登记出席功能的记录真实项目中的数据库往往非常庞大，所以我们第一步最好用match做一个筛选，因为只有第一步用match可以用到索引，提高查询速度：123db.groupstudent.aggregate( &#123;$match: &#123;present:&#123;$exists: true&#125;&#125;&#125;) 查询结果为:123456&#123; "_id" : "1_2", "sid" : 1, "gid" : 2, "present" : [ 2, 3, 4 ] &#125;&#123; "_id" : "1_3", "sid" : 1, "gid" : 3, "present" : [ 1, 4, 5 ] &#125;&#123; "_id" : "2_1", "sid" : 2, "gid" : 1, "present" : [ 2, 3 ] &#125;&#123; "_id" : "2_2", "sid" : 2, "gid" : 2, "present" : [ 1, 4 ] &#125;&#123; "_id" : "3_1", "sid" : 3, "gid" : 1, "present" : [ 4, 5 ] &#125;&#123; "_id" : "3_3", "sid" : 3, "gid" : 3, "present" : [ 1, 2, 3, 4 ] &#125; 2.映射需要处理的字段正是情况下每条数据可不止这些字段，为了让后面的处理更快，我们只保留需要使用的字段，下面加一层聚合：1234db.groupstudent.aggregate( &#123;$match: &#123;present:&#123;$exists: true&#125;&#125;&#125;, &#123;$project: &#123;_id: 0,sid:1, gid:1, presentDay:"$present"&#125;&#125;) 查询结果为:123456&#123; "sid" : 1, "gid" : 2, "presentDay" : [ 2, 3, 4 ] &#125;&#123; "sid" : 1, "gid" : 3, "presentDay" : [ 1, 4, 5 ] &#125;&#123; "sid" : 2, "gid" : 1, "presentDay" : [ 2, 3 ] &#125;&#123; "sid" : 2, "gid" : 2, "presentDay" : [ 1, 4 ] &#125;&#123; "sid" : 3, "gid" : 1, "presentDay" : [ 4, 5 ] &#125;&#123; "sid" : 3, "gid" : 3, "presentDay" : [ 1, 2, 3, 4 ] &#125; 3.分离数组元素数组元素在聚合中不太好直接处理，所以我们把它分离出来，每个元素单独分离出一条信息，我们使用unwind关键字：12345db.groupstudent.aggregate( &#123;$match: &#123;present:&#123;$exists: true&#125;&#125;&#125;, &#123;$project: &#123;_id: 0,sid:1, gid:1, presentDay:"$present"&#125;&#125;, &#123;$unwind:"$presentDay"&#125;) 查询结果为:12345678910111213141516&#123; "sid" : 1, "gid" : 2, "presentDay" : 2 &#125;&#123; "sid" : 1, "gid" : 2, "presentDay" : 3 &#125;&#123; "sid" : 1, "gid" : 2, "presentDay" : 4 &#125;&#123; "sid" : 1, "gid" : 3, "presentDay" : 1 &#125;&#123; "sid" : 1, "gid" : 3, "presentDay" : 4 &#125;&#123; "sid" : 1, "gid" : 3, "presentDay" : 5 &#125;&#123; "sid" : 2, "gid" : 1, "presentDay" : 2 &#125;&#123; "sid" : 2, "gid" : 1, "presentDay" : 3 &#125;&#123; "sid" : 2, "gid" : 2, "presentDay" : 1 &#125;&#123; "sid" : 2, "gid" : 2, "presentDay" : 4 &#125;&#123; "sid" : 3, "gid" : 1, "presentDay" : 4 &#125;&#123; "sid" : 3, "gid" : 1, "presentDay" : 5 &#125;&#123; "sid" : 3, "gid" : 3, "presentDay" : 1 &#125;&#123; "sid" : 3, "gid" : 3, "presentDay" : 2 &#125;&#123; "sid" : 3, "gid" : 3, "presentDay" : 3 &#125;&#123; "sid" : 3, "gid" : 3, "presentDay" : 4 &#125; 4.按兴趣小组及日期分组逐渐回到正题了，我们最终的结果需要查询每个兴趣小组每天的出席学生，所以自然要按照presentDay和gid分组：123456db.groupstudent.aggregate( &#123;$match: &#123;present:&#123;$exists: true&#125;&#125;&#125;, &#123;$project: &#123;_id: 0,sid:1, gid:1, presentDay:"$present"&#125;&#125;, &#123;$unwind:"$presentDay"&#125;, &#123;$group:&#123; _id: &#123;gid:"$gid", presentDay:"$presentDay"&#125;, sids:&#123;$addToSet:"$sid"&#125; &#125;&#125;) $group需要定义_id和聚合方法，所以第一个参数必须是_id,id中包含gid和presentDay，聚合方法可以有很多包括$sum累加和$count计数等等，我们现在要学生列表，所以我们用$addToSet，把学生组合成一个数组。一下是查询结果：12345678910111213&#123; "_id" : &#123; "gid" : 3, "presentDay" : 3 &#125;, "sids" : [ 3 ] &#125;&#123; "_id" : &#123; "gid" : 1, "presentDay" : 5 &#125;, "sids" : [ 3 ] &#125;&#123; "_id" : &#123; "gid" : 3, "presentDay" : 1 &#125;, "sids" : [ 3, 1 ] &#125;&#123; "_id" : &#123; "gid" : 3, "presentDay" : 5 &#125;, "sids" : [ 1 ] &#125;&#123; "_id" : &#123; "gid" : 1, "presentDay" : 3 &#125;, "sids" : [ 2 ] &#125;&#123; "_id" : &#123; "gid" : 2, "presentDay" : 4 &#125;, "sids" : [ 2, 1 ] &#125;&#123; "_id" : &#123; "gid" : 3, "presentDay" : 2 &#125;, "sids" : [ 3 ] &#125;&#123; "_id" : &#123; "gid" : 2, "presentDay" : 3 &#125;, "sids" : [ 1 ] &#125;&#123; "_id" : &#123; "gid" : 2, "presentDay" : 2 &#125;, "sids" : [ 1 ] &#125;&#123; "_id" : &#123; "gid" : 1, "presentDay" : 4 &#125;, "sids" : [ 3 ] &#125;&#123; "_id" : &#123; "gid" : 3, "presentDay" : 4 &#125;, "sids" : [ 3, 1 ] &#125;&#123; "_id" : &#123; "gid" : 1, "presentDay" : 2 &#125;, "sids" : [ 2 ] &#125;&#123; "_id" : &#123; "gid" : 2, "presentDay" : 1 &#125;, "sids" : [ 2 ] &#125; 5.为组合每天的列表做准备现在我们要把同一个兴趣小组的数据再组合在一起才能达到想要的效果：1234567db.groupstudent.aggregate( &#123;$match: &#123;present:&#123;$exists: true&#125;&#125;&#125;, &#123;$project: &#123;_id: 0,sid:1, gid:1, presentDay:"$present"&#125;&#125;, &#123;$unwind:"$presentDay"&#125;, &#123;$group:&#123; _id: &#123;gid:"$gid", presentDay:"$presentDay"&#125;, sids:&#123;$addToSet:"$sid"&#125; &#125;&#125;, &#123;$project: &#123;_id: false,gid:"$_id.gid", "presentStudentsOfDays": &#123;k:&#123;$toString:"$_id.presentDay"&#125;, v: "$sids"&#125;&#125;&#125;) 这里又用了$project,为了好看顺便把上一步的数据扁平化;另外把presentStudentsOfDays映射成一个对象，包含上一步的presentDay和sids，分别命名为k和v，并且把$_id.presentDay转化成了字符串，这么做是为了下下步使用$arrayToObject转换成对象做准备，关于$arrayToObject可以查看文档。我们看下效果：12345678910111213&#123; "gid" : 3, "presentStudentsOfDays" : &#123; "k" : "3", "v" : [ 3 ] &#125; &#125;&#123; "gid" : 2, "presentStudentsOfDays" : &#123; "k" : "1", "v" : [ 2 ] &#125; &#125;&#123; "gid" : 1, "presentStudentsOfDays" : &#123; "k" : "2", "v" : [ 2 ] &#125; &#125;&#123; "gid" : 3, "presentStudentsOfDays" : &#123; "k" : "4", "v" : [ 3, 1 ] &#125; &#125;&#123; "gid" : 1, "presentStudentsOfDays" : &#123; "k" : "3", "v" : [ 2 ] &#125; &#125;&#123; "gid" : 3, "presentStudentsOfDays" : &#123; "k" : "5", "v" : [ 1 ] &#125; &#125;&#123; "gid" : 3, "presentStudentsOfDays" : &#123; "k" : "1", "v" : [ 3, 1 ] &#125; &#125;&#123; "gid" : 1, "presentStudentsOfDays" : &#123; "k" : "5", "v" : [ 3 ] &#125; &#125;&#123; "gid" : 2, "presentStudentsOfDays" : &#123; "k" : "4", "v" : [ 2, 1 ] &#125; &#125;&#123; "gid" : 3, "presentStudentsOfDays" : &#123; "k" : "2", "v" : [ 3 ] &#125; &#125;&#123; "gid" : 2, "presentStudentsOfDays" : &#123; "k" : "3", "v" : [ 1 ] &#125; &#125;&#123; "gid" : 1, "presentStudentsOfDays" : &#123; "k" : "4", "v" : [ 3 ] &#125; &#125;&#123; "gid" : 2, "presentStudentsOfDays" : &#123; "k" : "2", "v" : [ 1 ] &#125; &#125; 6.按gid分组这回要把多个gid的条目合并了，很简单$group就行，和之前差不多：12345678db.groupstudent.aggregate( &#123;$match: &#123;present:&#123;$exists: true&#125;&#125;&#125;, &#123;$project: &#123;_id: 0,sid:1, gid:1, presentDay:"$present"&#125;&#125;, &#123;$unwind:"$presentDay"&#125;, &#123;$group:&#123; _id: &#123;gid:"$gid", presentDay:"$presentDay"&#125;, sids:&#123;$addToSet:"$sid"&#125; &#125;&#125;, &#123;$project: &#123;_id: false,gid:"$_id.gid", "presentStudentsOfDays": &#123;k:&#123;$toString:"$_id.presentDay"&#125;, v: "$sids"&#125;&#125;&#125;, &#123;$group:&#123; _id: "$gid", presentStudentsOfDays:&#123;$addToSet:"$presentStudentsOfDays"&#125; &#125;&#125;) 查询结果：123&#123; "_id" : 1, "presentStudentsOfDays" : [ &#123; "k" : "4", "v" : [ 3 ] &#125;, &#123; "k" : "3", "v" : [ 2 ] &#125;, &#123; "k" : "5", "v" : [ 3 ] &#125;, &#123; "k" : "2", "v" : [ 2 ] &#125; ] &#125;&#123; "_id" : 2, "presentStudentsOfDays" : [ &#123; "k" : "2", "v" : [ 1 ] &#125;, &#123; "k" : "3", "v" : [ 1 ] &#125;, &#123; "k" : "4", "v" : [ 2, 1 ] &#125;, &#123; "k" : "1", "v" : [ 2 ] &#125; ] &#125;&#123; "_id" : 3, "presentStudentsOfDays" : [ &#123; "k" : "1", "v" : [ 3, 1 ] &#125;, &#123; "k" : "5", "v" : [ 1 ] &#125;, &#123; "k" : "4", "v" : [ 3, 1 ] &#125;, &#123; "k" : "2", "v" : [ 3 ] &#125;, &#123; "k" : "3", "v" : [ 3 ] &#125; ] &#125; 7.数组转对象现在我们已经很接近我们的结果了，只需要把presentStudentsOfDays转换成需要的对象，要用到刚才说的$arrayToObject了：123456789db.groupstudent.aggregate( &#123;$match: &#123;present:&#123;$exists: true&#125;&#125;&#125;, &#123;$project: &#123;_id: 0,sid:1, gid:1, presentDay:"$present"&#125;&#125;, &#123;$unwind:"$presentDay"&#125;, &#123;$group:&#123; _id: &#123;gid:"$gid", presentDay:"$presentDay"&#125;, sids:&#123;$addToSet:"$sid"&#125; &#125;&#125;, &#123;$project: &#123;_id: false,gid:"$_id.gid", "presentStudentsOfDays": &#123;k:&#123;$toString:"$_id.presentDay"&#125;, v: "$sids"&#125;&#125;&#125;, &#123;$group:&#123; _id: "$gid", presentStudentsOfDays:&#123;$addToSet:"$presentStudentsOfDays"&#125; &#125;&#125;, &#123;$project: &#123;_id:0, gid: "$_id", presentStudentsOfDays:&#123;$arrayToObject:"$presentStudentsOfDays"&#125;&#125;&#125;) 查询结果：123&#123; "gid" : 1, "presentStudentsOfDays" : &#123; "4" : [ 3 ], "3" : [ 2 ], "5" : [ 3 ], "2" : [ 2 ] &#125; &#125;&#123; "gid" : 2, "presentStudentsOfDays" : &#123; "2" : [ 1 ], "3" : [ 1 ], "4" : [ 2, 1 ], "1" : [ 2 ] &#125; &#125;&#123; "gid" : 3, "presentStudentsOfDays" : &#123; "1" : [ 3, 1 ], "5" : [ 1 ], "4" : [ 3, 1 ], "2" : [ 3 ], "3" : [ 3 ] &#125; &#125; 完成！这回查询常用的有$match/$group/$project，不太常用的有$unwind/$addToSet/$arrayToObject。这个结果在代码里基本上可以直接拿来用了，并不需要后端再做什么处理，毕竟代码写起来要比聚合复杂的多，效率也低，堆栈甚至不一定放得下。最后再提一句，真实数据库里数据庞大，在聚合时mongodb内存文档上限时128M，超过这个数值就需要手动调成硬盘去处理啦，代码如下：123456db.groupstudent.aggregate( [各种聚合], &#123; allowDiskUse: true &#125;) 再见！👋]]></content>
      <categories>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeScript实现设计模式（六）-- 代理模式]]></title>
    <url>%2F2019%2F07%2F23%2FTypeScript%E5%AE%9E%E7%8E%B0%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E5%85%AD%EF%BC%89-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理模式（Proxy Pattern）：为其他对象提供一种代理以控制对这个对象的访问 假设我们要实现一个用户管理接口：123456789/** * @file IUserManager.ts */export default interface IUserManager &#123; getUser(name: string): string; addUser(name: string): string; delUser(name: string): string; getUserList():string[];&#125; 然后实现一下真实用户管理类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * @file UserManager.ts */import IUserManager from "./IUserManager";export default class UserManager implements IUserManager &#123; private static userList: string[]; public constructor() &#123; UserManager.userList = []; UserManager.userList.push("Tom"); UserManager.userList.push("Jacob"); UserManager.userList.push("Jerry"); &#125; public getUser(name: string): string &#123; let index = UserManager.userList.indexOf(name); if (index != -1) &#123; return UserManager.userList[index]; &#125; else &#123; throw new Error(`Can not find $&#123;name&#125;.`); &#125; &#125; public addUser(name: string):string &#123; let index = UserManager.userList.indexOf(name); if (index != -1) &#123; throw new Error(`$&#123;name&#125; has already exists.`); &#125; else &#123; UserManager.userList.push(name); return name; &#125; &#125; public delUser(name: string):string &#123; let index = UserManager.userList.indexOf(name); if (index != -1) &#123; UserManager.userList.splice(index, 1); return name; &#125; else &#123; throw new Error(`can not find $&#123;name&#125;`); &#125; &#125; public getUserList(): string[] &#123; return UserManager.userList; &#125;&#125; 代理类形式很简单，我们就不一步步推演了；下面我们就实现一个代理：1234567891011121314151617181920212223242526272829/** * @file UserManagerProxy */import IUserManager from './IUserManager';import UserManager from './UserManager';export default class UserManagerProxy implements IUserManager &#123; private userManager:IUserManager; public constructor(_userManager: IUserManager) &#123; this.userManager = _userManager; &#125; public getUser(name: string):string &#123; return this.userManager.getUser(name); &#125; public addUser(name: string):string &#123; return this.userManager.addUser(name); &#125; public delUser(name: string):string &#123; return this.userManager.delUser(name); &#125; public getUserList():string[] &#123; return this.userManager.getUserList(); &#125;&#125; 可以看到代理类和被代理类都是对IUserManager的实现，代理实例对帮助被代理实例执行其方法，实现访问控制；我们再看下标准场景类：123456789101112/** * @file client.ts */import UserManager from './UserManager';import UserManagerProxy from './UserManagerProxy';let userManager = new UserManager();let userManagerProxy = new UserManagerProxy(userManager);let userList = userManagerProxy.getUserList();console.debug(userList);//stdout: [ 'Tom', 'Jacob', 'Jerry' ] ok, 这就是最简单的代理模式，用一个proxy实例代替正真的产品去执行其方法。但是在这个例子里好像看不出代理模式有什么用呀？好的，那么我们加点料。用户管理是个复杂的系统，针对用户操作，我们首先要确认执行者有没有权限，在执行成功后记录管理员操作日志。这些代码写在哪里？自然是写在代理中，被代理的实例本身只需要关注最原始的功能，让代理执行其他复杂的处理流程。想象一下如果不用模式你会怎么做？一个方法里先写了权限判断，再写逻辑主体，最后再写操作日志。这完全不符合单一职责原则，而代理模式能很好的解决这个麻烦：1234567891011121314151617181920212223242526272829303132333435/** * @file UserManagerProxy */import IUserManager from './IUserManager';//import UserManager from './UserManager';export default class UserManagerProxy implements IUserManager &#123; private userManager:IUserManager; public constructor(_userManager: IUserManager) &#123; this.userManager = _userManager; &#125; public getUser(name: string):string &#123; console.log("正在检查权限"); return this.userManager.getUser(name); &#125; public addUser(name: string):string &#123; console.log("正在检查权限"); return this.userManager.addUser(name); console.log("正在记录操作日志"); &#125; public delUser(name: string):string &#123; console.log("正在检查权限"); return this.userManager.delUser(name); console.log("正在记录操作日志"); &#125; public getUserList():string[] &#123; console.log("正在检查权限"); return this.userManager.getUserList(); &#125;&#125; 还是按照原来的方式执行，结果如下：123正在检查权限正在记录操作日志[ 'Tom', 'Jacob', 'Jerry' ] 代理模式自然根据具体情况有各种扩展和变种。我暂时不一一列举了，如果项目里有比较好的实践，我会再回来写一写。这里我再写一种比较复杂的代理形式。假设UserManager需要扩展很多方法， 按照现在的方式，如果我要求每个方法都要检查权限和写操作日志， 那代理类需要把所有方法实现一遍，并加上检查权限和写操作日志。这种形式可能太麻烦了，所以我们要实现动态代理，也就是实现动态获取实例的方法并代理其执行。这点在js中倒是非常好实现。首先我们要脱离ts， 用js写一个动态代理类，这个动态代理可以代理所有的类：12345678910111213141516/** * @file DynamicProxy *//* jshint esversion: 6 */function DynamicProxy(_class, _handler) &#123; let proxy = new _class(); for (let funcName in _class.prototype) &#123; if(typeof _class.prototype[funcName] == 'function') proxy[funcName] = function() &#123; return _handler.invoke(_class.prototype[funcName], arguments); &#125;; &#125; return proxy;&#125;module.exports = DynamicProxy; 这个类接收两个参数，一个是class，以方便我们找到类中的所有方法，另一个是handler，我们后面会实现一下，handler中可以定义“要怎么代理”，也就是执行正真的方法之前和之后要干什么。我们向proxy变量上面绑定了class中的所有方法，并通过handler中定义的方式执行，这就是动态代理啦。当然我们是在ts中使用，我们我们要定义一下申明文件： 1234567/** * @file DynamicProxy.d.ts */import InvocationHandler from './InvocationHandler';declare function DynamicProxy&lt;T&gt;(_class: new()=&gt; T, handler: InvocationHandler): T;export default DynamicProxy; 接着定义handler，增加权限判断和操作日志：1234567891011121314151617181920/** * @file UserManagerIH..ts */import UserManager from "./UserManager";import InvocationHandler from './InvocationHandler';export default class UserManagerIH extends InvocationHandler &#123; private userManager: UserManager; public constructor(_userManager: UserManager) &#123; this.userManager = _userManager; &#125; public invoke(method: Function, args: any[]) &#123; console.log("正在检查权限"); let result = method.apply(this.userManager, args); console.log("正在记录操作日志"); return result; &#125;&#125; IH表示InvocationHandler，这个抽象类就一个invoke方法，自己实现一下吧。好啦，method.apply就是在执行真正的方法，前后加上了检查权限和操作记录。如果你还需要方法名来区分方法之间的微小区别，这里也可以加一个funcName参数。我举得例子现在还不一定是最佳方案，但是大致形式是这样的，一个动态代理动态绑定所有方法，一个IH定义各种处理流程。ok， 我们最后来看场景：1234567891011121314151617181920/** * @file client.ts */import UserManager from './UserManager';import DynamicProxy from './DynamicProxy';import UserManagerIH from './UserManagerIH';let userManager = new UserManager();let handler = new UserManagerIH(userManager);let proxy = DynamicProxy(UserManager, handler);let userList = proxy.getUserList();console.debug(userList);// stdout://正在检查权限//正在记录操作日志//[ 'Tom', 'Jacob', 'Jerry' ] 神奇吧，我并没有定义一个代理类把被代理对象的方法一个一个实现一遍，但是可以通过动态代理调用所有方法这就是动态代理。到这里一般都会提到面向切面编程（AOP，有兴趣可以查下），具体业务逻辑往往是分层的，就比如我们的UserManager， 需要权限判断，需要写日志，甚至需要通知，这里的每一层都是一个切面；如果每个方法都把这些曾都实现一遍，想想就觉得乱套，而且不仅仅是UserManager如何，其他什么什么Manager也要实现；当你实现了上百个接口以后，突然要改通接口，想想有多痛苦吧。代理模式就是一个很好的解决方案，让各个分层职责清晰，扩展性高。 代理模式的形式其实多种多样，应用也十分广泛，如果看到各种源码中有比较好的例子，我会再回来补充。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>设计模式</tag>
        <tag>TypeScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeScript实现设计模式（五）-- 建造者模式]]></title>
    <url>%2F2019%2F07%2F16%2FTypeScript%E5%AE%9E%E7%8E%B0%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%BA%94%EF%BC%89-%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[建造者模式（Builder Pattern）:将一个复杂对象的构建与其表示分离，使得同样的构建过程可以创建不同的表示。 我们先预定义一些电脑组件以供使用，假设组装一台电脑需要主板、中央处理器、内存、机箱：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859abstract class Motherboard &#123; public abstract toString(): string;&#125;class ASUSMotherboard extends Motherboard &#123; public toString(): string &#123; return "ASUS Motherboard"; &#125;&#125;class GIGAMotherboard extends Motherboard &#123; public toString(): string &#123; return "GIGA Motherboard"; &#125;&#125;//...abstract class CPU &#123; public abstract toString(): string;&#125;class IntelCPU extends CPU &#123; public toString(): string &#123; return "Intel CPU"; &#125;&#125;class AMDCPU extends CPU &#123; public toString(): string &#123; return "AMD CPU"; &#125;&#125;//...abstract class Memory &#123; public abstract toString(): string;&#125;class KingstonMemory extends Memory &#123; public toString(): string &#123; return "Kingstin Memory"; &#125;&#125;class CorsairMemory extends Memory &#123; public toString(): string &#123; return "Corsair Memory"; &#125;&#125;//...abstract class Crate &#123; public abstract toString(): string;&#125;class AigoCrate extends Crate &#123; public toString(): string &#123; return "Aigo Crate"; &#125;&#125;class SamaCrate extends Crate &#123; public toString(): string &#123; return "Sama Crate"; &#125;&#125;//... 如果我们想组装一台电脑，假设电脑类是这样的：1234567891011121314151617181920212223class Computer &#123; private motherboard: Motherboard; private cpu: CPU; private memory: Memory; private crate: Crate; public constructor( motherboard: Motherboard, cpu: CPU, memory: Memory, crate: Crate ) &#123; this.motherboard = motherboard; this.cpu = cpu; this.memory = memory; this.crate = crate; &#125; public boot():void &#123; console.log('booting....'); if(this.motherboard &amp;&amp; this.cpu &amp;&amp; this.memory) &#123; console.log('success!!'); &#125; &#125;&#125; 很好理解的一个类，构建时把组件都给Computer， 然后boot启动就好了：123456789101112131415let motherboard = new ASUSMotherboard();let cpu = new IntelCPU();let memory = new KingstonMemory();let crate = new AigoCrate();let computer = new Computer( motherboard, cpu, memory, crate);computer.boot();//stdout://booting....//success!! 写到这里想一想有哪些问题呢？ 第一，作为客户，我只想要一台电脑，虽然我可能知道我要的是华硕主板，金士顿的内存条，但是我并不需要知道这些零件如何构建出来；我的目的是要一台电脑，而我现在需要知道5个类，主板类、cpu类、内存类…；这显然违反了迪米特法则，也就是‘我知道的太多了’； 第二，上面写的这个Computer类太简单了，在构建之初就已经是可用状态，而现实中的某些类由于构建流程复杂，甚至需要异步网络请求；比如MongoClient，需要与MongoDB连接完成才处于可调用的状态，其构建过程不是constructor就能完成的。当然配一台电脑也不是一步到位的，所以我们稍微改复杂点再来解决这两个问题，Computer是一个产品所以通常会实现模板方法（关于模板方法模式见上一章），先定义一下Computer的虚类，保证Computer的扩展性：12345678910111213141516171819202122232425262728293031323334353637383940abstract class Computer &#123; private motherboard: Motherboard; private cpu: CPU; private memory: Memory; private crate: Crate; private builtUp: boolean = false; public constructor( motherboard: Motherboard, cpu: CPU, memory: Memory, crate: Crate ) &#123; this.motherboard = motherboard; this.cpu = cpu; this.memory = memory; this.crate = crate; &#125; protected abstract buildMotherboard(): Computer; protected abstract buildCPU(): Computer; protected abstract buildMemory(): Computer; protected abstract buildCrate(): Computer; public buildup() &#123; try &#123; this.buildMotherboard() .buildCPU() .buildMemory() .buildCrate(); &#125; catch (e) &#123; throw e; &#125; this.builtUp = true; &#125; public boot(): void &#123; console.log("booting...."); if (this.motherboard &amp;&amp; this.cpu &amp;&amp; this.memory) &#123; console.log("success!!"); &#125; &#125;&#125; buildup是把电脑组装起来，是一个模板方法，子类只要实现其他组件的安装即可，我们来定义一台个人电脑：1234567891011121314151617181920212223242526class PersonalComputer extends Computer &#123; public constructor( motherboard: Motherboard, cpu: CPU, memory: Memory, crate: Crate ) &#123; super(motherboard, cpu, memory, crate); &#125; protected buildMotherboard(): PersonalComputer&#123; console.log("building motherboard"); return this; &#125; protected buildCPU(): PersonalComputer &#123; console.log("building motherboard"); return this; &#125; protected buildMemory(): PersonalComputer &#123; console.log("building motherboard"); return this; &#125; protected buildCrate(): PersonalComputer &#123; console.log("building motherboard"); return this; &#125;&#125; 好了，现在我们来解决刚才的问题，也就是“客户知道的太多了”的问题，相当于之前一直是客户自己来了找零件装电脑。现在来了几个新客户，进来就说“把你们这最贵的机子呈上来！”。这个时候用户只要最贵的，老板替他挑选好就行，并不需要他自己选怎么装，又因为有好几个订单，这时候怎么办？建造者模式这时候该发挥作用了，我们定义一个建造者专门处理这样的订单，考虑到以后还有其他形式的订单，所以我们先定义一个建造者虚类：123abstract class ComputerBuilder &#123; public abstract buildComputer(): Computer;&#125; 然后在定义一个最贵电脑的建造者：12345678910class MostExpensiveComputerBuilder &#123; public buildComputer(): Computer &#123; let motherboard = new ASUSMotherboard(); let cpu = new IntelCPU(); let memory = new KingstonMemory(); let crate = new AigoCrate(); let computer = new PersonalComputer(motherboard, cpu, memory, crate); return computer; &#125;&#125; 这样一来用户接触到的就只有MostExpensiveComputerBuilder这个类了：123let mostExpensiveComputerBuilder = new MostExpensiveComputerBuilder();let computer = mostExpensiveComputerBuilder.buildComputer();computer.boot(); 问题暂时解决了，店老板很满意，现在就要将这个模式扩展到其他订单上，比如家里老年人炒股想配台最便宜的电脑，实现方法其实和上面差不多，就不多写了。更多的还有经济型，游戏型等等， 导致电脑店现在品类越来越多了，用户又得接触很多很多builder，才知道店里有什么。为了方便用户找到自己想要的品类，我们做了一个小册子，罗列所有的品类。这个小册子就是建造者模式中的导演（Director），目前只要一个就够了，就不需要虚类了：123456789101112131415161718class ShopDirector &#123; private mostExpensiveComputerBuilder: ComputerBuilder = new MostExpensiveComputerBuilder(); private mostCheapComputerBuilder: ComputerBuilder = new MostCheapComputerBuilder(); private gamePlayComputerBuilder: ComputerBuilder = new GamePlayComputerBuilder(); public getMostExpensiveComputer(): Computer &#123; return this.mostExpensiveComputerBuilder.buildComputer(); &#125; public getMostCheapComputer(): Computer &#123; return this.mostCheapComputerBuilder.buildComputer(); &#125; public getGamePlayComputer(): Computer &#123; return this.gamePlayComputerBuilder.buildComputer(); &#125;&#125; 好啦，这就是整个建造者模式了。针对构建比较复杂的对象，构建顺序或者构建方法等最终会影响构建结果，所以我们需要增加一个建造者以防止模块外部直接接触对象。当建造者变多的时候我们可能又需要一个Director来约束建造者。相比于工厂方法模式，最大的区别就是工厂模式中的“产品”是简单构建的对象，不存在构建方法不同会影响结果。相比于模板方法模式，建造者模式向 “用户”输出的是一个模块，该模块中的方法可以直接调用以获得各种“产品”；而模板方法模式向“用户”输出的是一个模板，“用户”通过继承这个模板，并简单了解上层构建过程以实现自己的类。简单说就是建造者模式的“用户”在调用方法，而模板方法模式的“用户”在继承类。参考了几篇文章写的建造者模式，其实根据假设场景的不用，具体实现也都不太一样，但是核心是不变的，就是定义中的“将复杂对象的构建与其表示分离”。建造者模式就写到这。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>设计模式</tag>
        <tag>TypeScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeScript实现设计模式（四）-- 模板方法模式]]></title>
    <url>%2F2019%2F07%2F11%2FTypeScript%E5%AE%9E%E7%8E%B0%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E5%9B%9B%EF%BC%89-%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[模板方法模式（Template Method Pattern）: 定义一个操作中算法的框架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义算法的某些特定步骤。 这回我们还是以手机为例，但是具体到如何生产一部手机，所以我们定义生产iphone的流水线的抽象;一部iphone需要安装主板、安装核心科技、安装摄像头、安装外壳，然后把所有过程串联起来，但是每款iphone安装的方式又不尽相同，所以我们抽象了这些方法，让具体的生产线去实现如何安装： 1234567abstract class IPhonePipeline &#123; protected abstract installMainboard(): void; protected abstract installCoreTech(): void; protected abstract installCamera(): void; protected abstract installShell(): void; public abstract produceIPhone(): void;&#125; 好了，我们现在分别开一条iphone4s的生产线和iphone6plus的生产线：123456789101112131415161718192021222324252627282930313233343536373839404142434445class IPhone4SPipeline extends IPhonePipeline &#123; protected installMainboard(): void &#123; console.log('iphone4S installing Mainboard...'); &#125; protected installCoreTech(): void &#123; console.log('iphone4S installing CoreTech...'); &#125; protected installCamera(): void &#123; console.log('iphone4S installing Camera...'); &#125; protected installShell(): void &#123; console.log('iphone4S installing installShell...'); &#125; public produceIPhone(): void &#123; this.installMainboard(); this.installCoreTech(); this.installCamera(); this.installShell(); console.log('completed install iphone 4s'); &#125;&#125;class IPhone6plusPipeline extends IPhonePipeline &#123; protected installMainboard(): void &#123; console.log('iPhone6plus installing Mainboard...'); &#125; protected installCoreTech(): void &#123; console.log('iPhone6plus installing CoreTech...'); &#125; protected installCamera(): void &#123; console.log('iPhone6plus installing Camera...'); &#125; protected installShell(): void &#123; console.log('iPhone6plus installing installShell...'); &#125; public produceIPhone(): void &#123; this.installMainboard(); this.installCoreTech(); this.installCamera(); this.installShell(); console.log('completed install iPhone6plus'); &#125;&#125; 然后生产一下试试：12345678let pipeline = new IPhone4SPipeline();pipeline.produceIPhone();//stdout://iphone4S installing Mainboard...//iphone4S installing CoreTech...//iphone4S installing Camera...//iphone4S installing installShell...//completed install iphone 4s 每多一部iphone就可以多一条生产线，写法同上。写到这里你们发现什么没？安装各种模块的时候各不相同，可以理解，但是最终组装的时候方法都是完全一样的呀。所以我们找到了所有生产线的共性，就是produceIPhone，于是模板方法模式就派上用场了，相同的方法我们可以总结到模板里，而不需要每个生产线分别去实现，减少了很多麻烦不说，还保证了各个生产线不会生产错。那我们先修改模板类，也就是我们的生产线虚类：12345678910111213abstract class IPhonePipeline &#123; protected abstract installMainboard(): void; protected abstract installCoreTech(): void; protected abstract installCamera(): void; protected abstract installShell(): void; public produceIPhone(): void &#123; this.installMainboard(); this.installCoreTech(); this.installCamera(); this.installShell(); console.log('completed install iphone'); &#125;&#125; 一般情况下，模板方法模式要求模板方法增加final关键字，以防被子类覆写，但是TypeScript目前还没有final关键字，和final类似的关键字readonly也只能在属性中使用，所以目前，只能自己注意点别覆盖模板方法。 有了模板方法以后，我们的生产线就可以简单点了：1234567891011121314151617181920212223242526272829303132333435363738class IPhone4SPipeline extends IPhonePipeline &#123; protected installMainboard(): void &#123; console.log('iphone4S installing Mainboard...'); &#125; protected installCoreTech(): void &#123; console.log('iphone4S installing CoreTech...'); &#125; protected installCamera(): void &#123; console.log('iphone4S installing Camera...'); &#125; protected installShell(): void &#123; console.log('iphone4S installing installShell...'); &#125;&#125;class IPhone6plusPipeline extends IPhonePipeline &#123; protected installMainboard(): void &#123; console.log('iPhone6plus installing Mainboard...'); &#125; protected installCoreTech(): void &#123; console.log('iPhone6plus installing CoreTech...'); &#125; protected installCamera(): void &#123; console.log('iPhone6plus installing Camera...'); &#125; protected installShell(): void &#123; console.log('iPhone6plus installing installShell...'); &#125;&#125;let pipeline = new IPhone4SPipeline();pipeline.produceIPhone();//stdout://iphone4S installing Mainboard...//iphone4S installing CoreTech...//iphone4S installing Camera...//iphone4S installing installShell...//completed install iphone 这就是模板方法模式，是不是太简单了？再简单也是模式嘛。现在再提出一个问题，每个手机外壳都要上色，上色方法其实都一样，只不过需要上的颜色不同而已，这个时候就用到了模板方法模式的扩展。要申明的是子类重写produceIPhone是必须被禁止的，虽然可以这么做，那也只是因为ts没有final关键字而已。在这种情况下我们想让子类影响父类的方法怎么办？那我们要请出进场能见到的 钩子方法:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748enum Color &#123; White = 'white', Black = 'black', Sliver = 'sliver'&#125;;abstract class IPhonePipeline &#123; protected abstract installMainboard(): void; protected abstract installCoreTech(): void; protected abstract installCamera(): void; protected abstract installShell(): void; protected getPaintColor(): Color &#123; return Color.Black; &#125; public produceIPhone(): void &#123; this.installMainboard(); this.installCoreTech(); this.installCamera(); this.installShell(); console.log(`painting color $&#123;this.getPaintColor()&#125;`); console.log('completed install iphone'); &#125;&#125;class IPhone4SPipeline extends IPhonePipeline &#123; private color: Color = Color.White; protected installMainboard(): void &#123; console.log('iphone4S installing Mainboard...'); &#125; protected installCoreTech(): void &#123; console.log('iphone4S installing CoreTech...'); &#125; protected installCamera(): void &#123; console.log('iphone4S installing Camera...'); &#125; protected installShell(): void &#123; console.log('iphone4S installing installShell...'); &#125; public getPaintColor(): Color &#123; return this.color; &#125; public setColor(color: Color): boolean &#123; this.color = color; return true; &#125;&#125; 在虚类IPhonePipeline中我们看到定义了getPaintColor方法，固定返回黑色，这就是我们的钩子方法，子类IPhone4SPipeline通过覆写getPaintColor方法影响了父类produceIPhone方法的执行，有没有似曾相识？很多框架比如游戏服务器框架pomelo的通用组件类Component就是模板方法，实现一个Component就能让该组件被pomelo加载，并且提供的before/after等钩子函数让我们能控制被加载过程中执行的方法，而且我们可以无限扩展各种组件。 模板方法模式优势： 封装不变部分，扩展可变部分 提取公共部分代码，便于维护 行为由父类控制，子类实现 劣势： 阅读有点难度 使用场景： 有能提取的公共方法 重要复杂的算法 需要大量扩展的方法类 模板方法模式就写到这里。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>设计模式</tag>
        <tag>TypeScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeScript实现设计模式（三）-- 抽象工厂模式]]></title>
    <url>%2F2019%2F07%2F10%2FTypeScript%E5%AE%9E%E7%8E%B0%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%89%EF%BC%89-%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[抽象工厂模式（Abstruct Factory Pattern）：为创建一组相关或相互依赖的对象提供一个接口，而无须指定他们的具体类。笔者简单推演了一下工厂方法模式到抽象工厂模式的转变过程。 抽象工程模式其实就是工厂方法模式的扩展；这回我们举一个具体点的例子：3G时代的时候，苹果和华为都找富士康代工生产3G手机，我们先用工厂方法模式实现一下，和上一篇差不多： 123456789101112131415161718192021222324252627282930313233343536373839404142abstract class MobilePhone3G &#123; public abstract call(number: string): void; public abstract sendSMS(number: string, ctx: string): void;&#125;class Iphone4S extends MobilePhone3G &#123; public call(number: string): void &#123; console.log(`calling $&#123;number&#125;...`); &#125; public sendSMS(number: string, ctx: string): void &#123; console.log(`sending $&#123;ctx&#125; to $&#123;number&#125;`); &#125;&#125;class HuaweiMate extends MobilePhone3G &#123; public call(number: string): void &#123; console.log(`calling $&#123;number&#125;...`); &#125; public sendSMS(number: string, ctx: string): void &#123; console.log(`sending $&#123;ctx&#125; to $&#123;number&#125;`); &#125;&#125;abstract class Factory &#123; public abstract createMobilePhone3G&lt;T extends MobilePhone3G&gt;(C: new () =&gt; T): T;&#125;class FoxConnFactory extends Factory &#123; public createMobilePhone3G&lt;T extends MobilePhone3G&gt;(C: new () =&gt; T): T &#123; let phone: T = null; try &#123; phone = new C(); &#125; catch (e) &#123; console.error("produce phone failed！"); &#125; return phone; &#125;&#125;let factory = new FoxConnFactory();let phone = factory.createMobilePhone3G(Iphone4S);phone.call("15082888128"); //stdout: calling 15082888128... ok，很简单，富士康用一家工厂同时生产两个品牌的手机。但是这个方法遇到了第一个问题，那就是华为和苹果有各自的核心科技，组装方法并不一样，在一家工厂生产难免会碰到各种麻烦，为了体现这里麻烦，我们让苹果和华为手机的构造方法不一样一点，各自组装了自己的核心科技：1234567891011121314151617181920212223242526272829303132class Iphone4S extends MobilePhone3G &#123; appleSecretModule: string; public constructor(appleSecretModule: string) &#123; super(); this.appleSecretModule = appleSecretModule; &#125; public call(number: string): void &#123; console.log(`calling $&#123;number&#125;...`); &#125; public sendSMS(number: string, ctx: string): void &#123; console.log(`sending $&#123;ctx&#125; to $&#123;number&#125;`); &#125;&#125;class HuaweiMate extends MobilePhone3G &#123; huaweiSecretModule: number; public constructor(huaweiSecretModule: number) &#123; super(); this.huaweiSecretModule = huaweiSecretModule; &#125; public call(number: string): void &#123; console.log(`calling $&#123;number&#125;...`); &#125; public sendSMS(number: string, ctx: string): void &#123; console.log(`sending $&#123;ctx&#125; to $&#123;number&#125;`); &#125;&#125; 因为构造方法不一样了，用一个工厂生产显然不太合理，于是我们继承同一个工厂开设两家工厂，分别生产苹果和华为手机：12345678910111213141516171819202122232425class AppleFactory extends Factory &#123; public createMobilePhone3G&lt;T extends MobilePhone3G&gt;(C: new (appleSecretModule: string) =&gt; T): T &#123; let phone: T = null; let appleSecretModule: string = "UDIIKS@！##¥"; try &#123; phone = new C(appleSecretModule); &#125; catch (e) &#123; console.error("produce phone failed！"); &#125; return phone; &#125;&#125;class HuaweiFactory extends Factory &#123; public createMobilePhone3G&lt;T extends MobilePhone3G&gt;(C: new (huaweiSecretModule: number) =&gt; T): T &#123; let phone: T = null; let huaweiSecretModule: number = 100192; try &#123; phone = new C(huaweiSecretModule); &#125; catch (e) &#123; console.error("produce phone failed！"); &#125; return phone; &#125;&#125; 然后生产一台iphone4S：123let appleFactory = new AppleFactory();let iphone4S = appleFactory.createMobilePhone3G(Iphone4S);iphone4S.call("15082888128");//stdout: calling 15082888128... 经过现在的调整富士康的生产线的扩展性已经大大提高了，现在要是其他手机厂商需要代工，直接新建一个新的工厂即可，管你有什么核心科技都无所谓了。 又过了几年，移动网络进入了4G时代，各大厂商纷纷开发了4G手机,这个时候我们需要创建一下4G手机的虚类：1234abstract class MobilePhone4G &#123; public abstract call(number: string): void; public abstract sendSMS(number: string, ctx: string): void;&#125; 然后华为和苹果设计出了4G手机并且都保留了他们的核心科技：1234567891011121314151617181920212223242526272829303132class Iphone6Plus extends MobilePhone4G &#123; appleSecretModule: string; public constructor(appleSecretModule: string) &#123; super(); this.appleSecretModule = appleSecretModule; &#125; public call(number: string): void &#123; console.log(`calling $&#123;number&#125;...`); &#125; public sendSMS(number: string, ctx: string): void &#123; console.log(`sending $&#123;ctx&#125; to $&#123;number&#125;`); &#125;&#125;class HuaweiP9 extends MobilePhone4G &#123; huaweiSecretModule: number; public constructor(huaweiSecretModule: number) &#123; super(); this.huaweiSecretModule = huaweiSecretModule; &#125; public call(number: string): void &#123; console.log(`calling $&#123;number&#125;...`); &#125; public sendSMS(number: string, ctx: string): void &#123; console.log(`sending $&#123;ctx&#125; to $&#123;number&#125;`); &#125;&#125; 因为核心科技基本相同，生产苹果的工厂没必要分成两家工厂，其他的也一样，所以，我们在同一家工厂里同时生产3G和4G的手机：1234abstract class Factory &#123; public abstract createMobilePhone3G&lt;T extends MobilePhone3G&gt;(C: new () =&gt; T): T; public abstract createMobilePhone4G&lt;T extends MobilePhone3G&gt;(C: new () =&gt; T): T;&#125; 然后苹果手机工厂就变成这样：12345678910111213141516171819202122class AppleFactory extends Factory &#123; appleSecretModule: string = "UDIIKS@！##¥"; public createMobilePhone3G&lt;T extends MobilePhone3G&gt;(C: new (appleSecretModule: string) =&gt; T): T &#123; let phone: T = null; try &#123; phone = new C(this.appleSecretModule); &#125; catch (e) &#123; console.error("produce phone failed！"); &#125; return phone; &#125; public createMobilePhone4G&lt;T extends MobilePhone4G&gt;(C: new (appleSecretModule: string) =&gt; T): T &#123; let phone: T = null; try &#123; phone = new C(this.appleSecretModule); &#125; catch (e) &#123; console.error("produce phone failed！"); &#125; return phone; &#125;&#125; 目前我们不管是横向扩展还是纵向扩展，都没有问题了，简直完美，5G6G来了也不怕。经过上面几步，我们其实从最开始的工厂方法模式，过渡到了抽象工厂模式。当然最后还是要提一点，抽象工厂模式很庞大，看看我们上面的代码就知道了，并不是所有情况我们都需要一个抽象工厂，如果一个模块很显然需要在多个维度上扩展，那才可能考虑用这个模式。例如一个系统需要在Windows/Linux/Android上同时开发，我们并不需要开发多份代码，只需要用不同的工厂方法处理与不同系统的交互。 抽象方法模式就总结到这里，有什么写的不好的地方请多多指正。 这个代码高亮我一定要弄好它！！！·]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>设计模式</tag>
        <tag>TypeScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeScript实现设计模式（二）-- 工厂方法模式]]></title>
    <url>%2F2019%2F07%2F09%2FTypeScript%E5%AE%9E%E7%8E%B0%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%BA%8C%EF%BC%89-%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂方法模式（Factory Method Pattern）:定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法是使用频率最高的设计模式之一；根据具体情况有多个变种；以下是TypeScript的实现。 标准工厂方法模式首先我们需要一个产品的抽象层，用来约定所有产品需要实现哪些方法；interface和abstract class都可以对产品做抽象，选任何一种都可以，根据具体情况而定；这里举例用interface作为产品的抽象：1234interface Product &#123; m1(): void; m2(): void;&#125; 然后我们来实现两种产品：1234567891011121314151617181920class ProductA implements Product &#123; public m1(): void &#123; console.log('ProductA is calling func m1'); &#125; public m2(): void &#123; console.log('ProductA is calling func m2'); &#125;&#125;class ProductB implements Product &#123; public m1(): void &#123; console.log('ProductB is calling func m1'); &#125; public m2(): void &#123; console.log('ProductB is calling func m2'); &#125;&#125; 还需要一个工厂的抽象层，因为可能要建很多工厂；当然也有只需要一个工厂的场景，后面也会提到；实现如下：123abstract class AbstractFactory &#123; public abstract createProduct&lt;T extends Product&gt;(C: new () =&gt; T): T;&#125; 这里实现的是一个标准做法，可以传入要生产的产品的class来获得该产品；&lt;T extends Product&gt;定义了模板T为Product的实现；输入参数为Class而非实例，所以C的类型为new () =&gt; T，C的类型还有另一种写法，如下：123abstract class AbstractFactory &#123; public abstract createProduct&lt;T extends Product&gt;(C: &#123;new(): T; &#125;): T;&#125; 最后实现一下工厂：1234567891011class Factory extends AbstractFactory &#123; public createProduct&lt;T extends Product&gt;(C: new () =&gt; T): T &#123; let product: T = null; try &#123; product = new C(); &#125; catch (e) &#123; console.error("create product failed！"); &#125; return product; &#125;&#125; 生产一个产品试试：123let factory = new Factory();let product = factory.createProduct(ProductA);product.m1(); //ProductA is calling func m1 书里介绍过的的我就不多说啦，简单总结一下。我认为工厂方法模式主要提供了两层约束，第一层是约束了产品的实现，通过定义interface或者abstract class保证了产品的“质量”，即满足所需的所有要求；第二层约束是工厂，保证生产出来的是某一类产品，而不是其他什么类的什么产品，想象一下如果不用模式我们一定是用switch来提供各种产品，那switch中返回的是什么是不是完全不可控呢。 简单工厂模式正如刚才说的，有的时候我们真的不需要一个抽象工厂类，因为在可见的未来都不太可能需要多个工厂，那么这个时候我们也不需要强行增加复杂度，我们只需要一个简单工厂，并且提供一个静态工厂方法即可，实现如下：1234567891011class SimpleFactory &#123; public static createProduct&lt;T extends Product&gt;(C: new () =&gt; T): T &#123; let product: T = null; try &#123; product = new C(); &#125; catch (e) &#123; console.error("create product failed！"); &#125; return product; &#125;&#125; 生产产品也略有区别，调用的是静态方法：12let product = SimpleFactory.createProduct(ProductA);product.m1();//ProductA is calling func m1 延迟初始化延迟初始化（Lazy Initialization），就是保留创建的对象，以备再次使用；我举个例子，比如我们开发一个聊天系统，聊天系统中有各种频道，频道被创建时是需要被保留的，并且有可能要控制频道数量，这时候用延迟初始化的方式就很好了，来看我的代码实现：12345678910111213141516171819202122232425262728abstract class Channel &#123; public abstract add(user: string): boolean; public abstract kick(user: string): boolean;&#125;class GroupChannel extends Channel &#123; public add(user: string): boolean &#123; return true; &#125; public kick(user: string): boolean &#123; return true; &#125;&#125;class ChannelService &#123; private static readonly channelMap: Map&lt;string, Channel&gt; = new Map(); public static createChannel(name: string): Channel &#123; let channel: Channel = null; if (this.channelMap.has(name)) &#123; channel = this.channelMap.get(name); &#125; else &#123; channel = new GroupChannel(); this.channelMap.set(name, channel); &#125; return channel; &#125;&#125; 代码其实很好理解，ChannelService中用一个Map保存所有channel，这里用到了一个readonly关键字，它和java中的final是等效的，表示被初始化后不可变；除了一个静态的Map我们还实现了静态方法createChannel，如果能找到对应的channel则返回，如果没找到，则创建再返回，这样新的用户就能进入以前创建过的频道。 工厂方法模式几乎没什么缺点，代码结构清晰，可扩展性强，并且使用非常频繁；但是要活学活用，设计模式提供的只是参考，具体如何运用还是得和实际情况相结合。 这个代码高亮好像对ts支持的不太好，我想想办法换一个╮(╯ ╰)╭]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>设计模式</tag>
        <tag>TypeScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeScript实现设计模式（一）-- 单例模式]]></title>
    <url>%2F2019%2F07%2F06%2FTypeScript%E5%AE%9E%E7%8E%B0%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[最近在阅读《设计模式之禅》，一方面想实践实践，另一方面ts和java的实现有很多不同之处，所以引用一些书中的例子用ts的方法实现；具体设计模式详解我就不在这写啦，毕竟书里和掘金上已经有很多；可能不会所有模式都写，看情况吧；今天先写第一个：单例模式（Singleton）。 饱汉模式即申明时就创建单例，书中没提饱汉饿汉两个名次，但是两种实现都写了。下面是饱汉模式的实现：12345678910111213141516171819/** * @file Emperor.js */class Emperor &#123; private static emperor: Emperor = new Emperor("嬴政"); private name: string; private constructor(name: string) &#123; this.name = name; &#125; public static getInstance(): Emperor &#123; return Emperor.emperor; &#125; public say(): void &#123; console.log(`我是皇帝$&#123;this.name&#125;`); &#125;&#125; 有一个static变量emperor和static方法getInstance，是实现单例模式的关键；ts的static关键字和java中的功能一样，我们看看编译出来的js代码：12345678910111213var Emperor = /** @class */ (function () &#123; function Emperor(name) &#123; this.name = name; &#125; Emperor.getInstance = function () &#123; return Emperor.emperor; &#125;; Emperor.prototype.say = function () &#123; console.log("\u6211\u662F\u7687\u5E1D" + this.name); &#125;; Emperor.emperor = new Emperor("嬴政"); return Emperor;&#125;()); 所以实际都是在Emperor类下面直接定义了emperor和getInstance，而不是在prototype下。因此调用他们和java也略有所区别，在getInstance中，使用了1return Emperor.emperor; 而不通过this或者直接使用emperor来访问；获取Emperor实例也一样,不用new关键字，我们这么写：12let emperor = Emperor.getInstance();emperor.say(); //stdout: 我是皇帝嬴政 饿汉模式即在第一次使用的时候创建实例；nodejs是单线程的所以不需要考虑线程安全，所以这里简单多了：12345678910111213141516171819class Emperor &#123; private static emperor: Emperor = null; private name: string; private constructor(name: string) &#123; this.name = name; &#125; public static getInstance(): Emperor &#123; if (Emperor.emperor == null) &#123; Emperor.emperor = new Emperor("嬴政"); &#125; return Emperor.emperor; &#125; public say(): void &#123; console.log(`我是皇帝$&#123;this.name&#125;`); &#125;&#125; ts实现单例模式就介绍到这里。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>设计模式</tag>
        <tag>TypeScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pm2功能概要]]></title>
    <url>%2F2019%2F06%2F27%2Fpm2%E5%8A%9F%E8%83%BD%E6%A6%82%E8%A6%81%2F</url>
    <content type="text"><![CDATA[pm2具体文件见官网，下面有链接；这里只是整理一下pm2的所有功能，用到的时候又个对照。 功能列表 多种配置文件形式；yml、json、js均支持； 应用启动脚本配置；简单的node app.js 和复杂的脚本启动均可配置； watch功能；检测文件变化并自动重启服务，在测试环境中非常常用； 以cluster为基础的多进程部署；instances、exec_mode；对于web应用来说相当于自动负载均衡； 可指定启动脚本执行的路径；也就是不用非得在项目目录下执行； 指定进程最大内存；max_memory_restart; 在内存超过该值时会重新启动； 日志相关；错误输出和其他输出是分开记录在文件中的，可改变默认日志路径；也可以指定是否将多个进程的日志集中在一起； 进程控制相关；指定启动时间、超时时间、自动重启等等； 可指定解释器；bash、python；但是目前我还没用过 可通过ssh方式远程发布（Deployment）；配置文件中可指定发布服务器信息；pm2命令和操作远程项目； 查看进程列表； 查看单独的进程日志或者多个进程的联合日志； 查看运行状态，cpu内存堆栈资源利用情况； 控制进程的启动暂停重置删除； 配置服务器重启后的自动恢复（Startup）； 支持安全退出进程；前提是代码中时通过process按照标准实现安全退出； 可配合keymetrics进行监控报警(Process Actions)；运维应该非常喜欢这个功能； 支持BabelJS， Typescript的source map，以追踪这些代码的错误源文件； pm2支持api；也就是说你可以通过api编写一个自己的管理软件； 管理node模块的发布和加载（Module System）；这个我还没试过； pm2可以和nginx一样作为静态文件的服务器；但是功能比较简单，测试用一用还是很方便的； 支持Docker CheatSheet1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Fork modepm2 start app.js --name my-api # Name process# Cluster modepm2 start app.js -i 0 # Will start maximum processes with LB depending on available CPUspm2 start app.js -i max # Same as above, but deprecated.pm2 scale app +3 # Scales `app` up by 3 workerspm2 scale app 2 # Scales `app` up or down to 2 workers total# Listingpm2 list # Display all processes statuspm2 jlist # Print process list in raw JSONpm2 prettylist # Print process list in beautified JSONpm2 describe 0 # Display all informations about a specific processpm2 monit # Monitor all processes# Logspm2 logs [--raw] # Display all processes logs in streamingpm2 flush # Empty all log filespm2 reloadLogs # Reload all logs# Actionspm2 stop all # Stop all processespm2 restart all # Restart all processespm2 reload all # Will 0s downtime reload (for NETWORKED apps)pm2 stop 0 # Stop specific process idpm2 restart 0 # Restart specific process idpm2 delete 0 # Will remove process from pm2 listpm2 delete all # Will remove all processes from pm2 list# Miscpm2 reset &lt;process&gt; # Reset meta data (restarted time...)pm2 updatePM2 # Update in memory pm2pm2 ping # Ensure pm2 daemon has been launchedpm2 sendSignal SIGUSR2 my-app # Send system signal to scriptpm2 start app.js --no-daemonpm2 start app.js --no-vizionpm2 start app.js --no-autorestart 相关网址pm2官网pm2文档]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>pm2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中使用grep在文件夹中搜索文件内容]]></title>
    <url>%2F2019%2F03%2F30%2F1000-Linux%E4%B8%AD%E4%BD%BF%E7%94%A8grep%E5%9C%A8%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E6%90%9C%E7%B4%A2%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[1grep -rnw '/path/to/somewhere' -e 'pattern' -r 表示递归后面的路径 -n 表示是否显示所有文件行数 -w 表示完全匹配 -l 可以显示文件内容 -e 后面的pattern是要搜索的内容，可以是正则表达式 例如我在我的博客代码里搜索类型为Linux的文章：1234567$ grep -rnw ./ -e 'categories:.*Linux'.//source/_posts/1000-Linux中使用grep在文件夹中搜索文件内容.md:7:categories: Linux.//source/_posts/在Ubuntu上配置iptables.md:7:categories: Linux.//source/_posts/siege（围攻）web压力测试工具.md:7:categories: Linux.//source/_posts/搭建shadowsocks.md:6:categories: Linux.//source/_posts/node+nginx搭建SSL.md:8:categories: Linux.//source/_posts/Linux创建新用户.md:6:categories: Linux 还有一个比较有用的flag: --include=&#39;pattern&#39;,可以用来搜索指定名称的文件，比如：1$ grep -rnw ./ -e 'categories:.*Linux' --include='*.md' grep是非常常用的命令，可以man grep获取更多相关信息。如果搜索这个需求比较频繁可以做成全局的小工具fif(Find in Folder)：1sudo echo grep -rnw \`pwd\` -e \$1 &gt; /usr/local/bin/fif &amp;&amp; chmod +x /usr/local/bin/fif 这样用：1fif 'categories:*Linux']]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2019%2F02%2F12%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[调试方式首先，我们可以利用文本编辑器自带的搜索功能测试自己写的正则表达式，atom、vscode等等都支持正则搜索；以atom作为例子，Ctrl/Cmd + F开启搜索框，并且点击右边正则和区分大小写的开关即可，上图： 然后在搜索框输入正则表达式就能看到是否正确匹配需要的字符串了，因此这里先给出一个后面要用到的调试文本，以供后面描述内容的调试:12345678910111213141516171819202122232425abcdefghijklmnopqurtuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890Ha HaHa HaHaHacatmatpatbat·tiny-calf.com321-555-4321123.555.1234123*555*1234800.555.1234900.555.1234Mr. SchaferMr TMrMr SmithMs DavisMrs. Robinson 转义符 .在正则中的意义是所有字符，包括空格不包括回车；所以在搜索框输入.时所有文本都会被选中；输入.测试本条 那么我们只想匹配.这个字符本身怎么办，那就只要在它之前加上转义符，即\；输入\.测试本条 如果要匹配字符\则需要转义它自己；输入\\测试本条 要匹配示例文本中的网址，输入tiny-calf\.com测试本条 正则中类似.的特殊字符字符总共有这几个，如果要匹配字符本身则都需要转义符：.[]{}()\^$|?*+，这几个特殊字符后面也会一一说明；本条自行测试 转义符+特殊字母以下几个特殊的字母在前面加上转义符以后在正则中有特殊含义，我们逐一看看： \d表示匹配数字 (0-9)；d表示Digit；而\D则表示非数字；输入 \d和\D测试本条 \w和\W也同理，w代表Word，也就是普通字符，包括a-z A-Z 0-9 _;则\w匹配普通字符，\W匹配非普通字符；输入 \w和\W测试本条 \s和\S也同理，s代表Space，这里的Space包括 空格、tab和回车空行；输入 \s和\S测试本条 字符串匹配以及[]的应用以上只讲了最基础的单个字符的匹配，把他们组合起来就是我们常用的字符串匹配了，例如示例中的电话号码：12345321-555-4321123.555.1234123*555*1234800.555.1234900.555.1234 匹配所有电话号码：数字位是\d，连接符号需要匹配所有字符所以可以用.:输入\d\d\d.\d\d\d.\d\d\d\d测试本条 只匹配连接符号是-.的电话号码：我们需要用到特殊字符[]，它代表一个单选，表示该位置可以是[]中内容的其中一个；这里连接位就可以用它表示：输入\d\d\d[.-]\d\d\d[.-]\d\d\d\d测试本条； 在上面一条的基础上，匹配开头是800或者900的电话号码：依然还是用[]实现，第一位数字有89两个选择，后面的00直接用普通字符表示即可；输入[89]00[.-]\d\d\d[.-]\d\d\d\d测试本条 []中可以用一个特殊含义的字符-表示数字或字符的范围，而不用把所有数字和字符都写出来，比如[0-9a-zA-Z]表示该位可以是所有数字和字母，所以上面一条也可以用这个实现：输入[8-9]00[.-]\d\d\d[.-]\d\d\d\d测试本条 还有一条我们用另一个文本来测试：1234catmatpatbat 匹配开头不是b，后面两位是at的单词：这里会用到了[]中的另一个特殊字符^表示“非”在括号内最前面加上即可：输入[^b]at测试本条 引用符号{}+?*{}+?*都用于将某一位的匹配规则引用到后面的N位中,因此他们都在某匹配规则的后方；{}表示让某一位的匹配重复应用到后面的确切的N位中，还是拿电话号码的文本作为例子：12345321-555-4321123.555.1234123*555*1234800.555.1234900.555.1234 上一节用\d\d\d表示三位数字，就可以用{}来简化；输入\d{3}.\d{3}.\d{4}测试本条 +?*用于表示不确定数量的引用，关于这些我们用另一个更合适的例子：123Mr SchaferMr TMr 我们来匹配Mr开头的所有名字：开头一定是Mr\s,注意有一个空格；后面要匹配所有字母，我们先写一个[a-zA-Z];然后我们要把[a-zA-Z]这个规则重复多次，分别使用+?*来看看效果 在正则后面增加+，+表示至少一个，所以效果应该是只有Mr这行没被选中；输入Mr\s[a-zA-Z]+测试本条 在正则后面增加?，?表示一个或没有，此时效果应该是Mr S、Mr T、Mr被选中了，为了匹配完整的一行字符串，我们在后面再加一个$表示匹配结束了，后面不应该有其他字符，此时现在我们应该看到只有Mr T被选中；输入Mr\s[a-zA-Z]?$测试本条 在正则后面增加*，*表示随便多少位，此时效果应该是所有行都被选中了输入Mr\s[a-zA-Z]*测试本条 集合符号()的应用集合符号的作用之一是方便引用符号{}+?*的使用，因为正常引用符号只能针对一位匹配规则进行引用，使用集合符号后，可以对多位的匹配规则进行引用，以下我们用一个网址的例子：1234https://www.google.comhttp://coreyms.comhttps://youtube.comhttps://www.nasa.gov 匹配所有url：这里的www有的有，有的没有，按照上面的经验我们应该要用到?，这里我们可以把www用集合符号括起来，对这个集合使用?；输入https?://(www\.)?(\w+)(\.\w+)测试本条 集合符号还有一个作用就是在正则的替换规则中，可以用数字指定某一个集合； 替换字符串，只保留一级二级域名：从上一条来看，一级二级域名分别处于第二个集合和第三个集合，那么此时我们只要在替换框里面输入$2$3,点替换所有，就可以实现目标了；replace框输入$2$3并点击ReplaceAll测试本条 集合符号中还可以使用特殊符号|来表示选择，比如我们想匹配上面的所有名字：123456Mr. SchaferMr TMrMr SmithMs DavisMrs. Robinson 匹配所有名字：输入 M(r|s|rs)\.?\s[A-Z]\w*测试本条 ^和$^和$分别匹配行的开头和结尾，在正则中我们可以把“行”看作以“回车”分割的字符串；所以当我们输入^Ha的时候，只匹配了Ha HaHa HaHaHa这行的最前面的Ha；而当我们输入Ha$或者HaHa$时则匹配了末尾的字符串 正则匹配邮箱典型练习先来一个邮箱列表方便调试：123CoreyMSchafer@gmail.comcorey.schafer@university.educorey-321-schafer@my-work.net 这里我提供一些答案，可以尝试读懂并测试他们的区别：1234[a-zA-Z]+@[a-zA-Z]+\.com[a-zA-Z.]+@[a-zA-Z]+\.(com|edu)[a-zA-Z0-9.-]+@[a-zA-Z.-]+\.(com|edu|net)[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+ 正则表达式查询表123456789101112131415161718192021. - 所有字符（包括空格不包括回车）\d - 数字 (0-9) d表示Digit\D - 非数字\w - 字符 (a-z, A-Z, 0-9, _) w表示Word\W - 非字符\s - 空格 (空格、tab和回车) s表示Space\S - 非空格^ - 匹配字符串的开头$ - 匹配字符串的结尾[] - 匹配在某范围内的一个字符[^ ] - 匹配不是该范围中的一个字符| - 或( ) - 集合* - 引用匹配规则 0次 或 1次 或 多次+ - 引用匹配规则 1次 或 多次? - 引用匹配规则 0次 或 1次&#123;3&#125; - 引用匹配规则 3次&#123;3,4&#125; - 引用匹配规则 3次或4次]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法总结]]></title>
    <url>%2F2019%2F01%2F25%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[简单总结一下几种常见的排序算法，包括冒泡排序、选择排序、插入排序、快速排序和堆排序 冒泡排序 平均时间复杂度O(n^2)；最坏时间复杂度O(n^2)；空间复杂度O(1)；稳定 算法原理从后往前，相邻两个数中较小的数放在前面，一次遍历下来，第一个就是最小的数；如此往复，数组前头就一直是有序数组，只需要冒泡后面的无序数组就行 python实现1234567def bubble_sort(arr): # 总共执行 总长-1 次 for i in xrange(len(arr)-1): # 从最后开始 相邻两个较小的数放在前面 for j in range(len(arr)-1 , i, -1): if arr[j] &lt; arr[j-1]: arr[j], arr[j-1] = arr[j-1], arr[j] 选择排序 平均时间复杂度O(n^2)；最坏时间复杂度O(n^2)；空间复杂度O(1)；不稳定 算法原理找出数组中最小的与第一位替换；这样数组前面就形成了有序数组，后面则是无序数组；再找出无序数组中最小的与第二位替换，以此类推 python实现1234567891011def select_sort(arr): for i in xrange(len(arr)): #记录最小值的索引 index = i #找到最小值 for j in range(i+1, len(arr)): if arr[j] &lt; arr[index]: index = j #替换最小值 if index != i: arr[i],arr[index] = arr[index],arr[i] 插入排序 平均时间复杂度O(n^2)；最坏时间复杂度O(n^2)；空间复杂度O(1)；稳定 算法原理先把数组第一个元素看作有序数组；同样的，数组前面就形成了有序数组，后面则是无序数组；从第二个元素开始，找到该元素应该插入到有序数组的位置，并插入，以此类推 python实现1234567891011def insert_sort(arr): for i in range(1, len(arr)): j = i - 1 #把准备插入的这个元素值先存起来 temp = arr[i] #把比这个元素大的元素后移一位 while j &gt;= 0 and temp &lt; arr[j]: arr[j+1] = arr[j] j -= 1 #插入 arr[j+1] = temp 快速排序 平均时间复杂度O(nlogn)；最坏时间复杂度O(n^2)；空间复杂度O(logn)；不稳定 算法原理以一个值位中间点，一开始就以数组的第一个元素作为中间点，把数组分为小于这个数的数组和大于这个数的数组；再把分开的这两个数组分别重复上面的操作，直到全部完成，该操作一般用递归完成； python实现123456789101112131415161718def quick_sort(arr): if len(arr) &lt;= 1: return arr # 小数组 less = [] # 大数组 greater = [] # 取第一个值作为中间值 pivot = arr.pop() # 判断元素并加入大小数组 for item in arr: if item &lt; pivot: less.append(item) else: greater.append(item) arr.append(pivot) # 递归结果 return quick_sort(less) + [pivot] + quick_sort(greater) 堆排序 平均时间复杂度O(nlogn)；最坏时间复杂度O(nlogn)；空间复杂度O(1)；不稳定 算法原理首先，我。。太难用文字解释了，先看下这个视频吧，传送门;ok,然后堆就是指视频里的二叉堆，上图：那么堆的存储结构就是这样的，上图：以上两个结构之间的对应是有这样的关系的：一个节点的子节点的索引就是2*i+1和2*i+2,反过来，父节点的下标就为子节点的(i-1)/2,此为后面编程的理论基础；有了这些概念以后，才是算法步骤啦；首先，如视频里的步骤，把整个数组先变成最大堆；然后，堆顶肯定是最大的数吧～那就和最后一位交换一下，那么数组末尾就是有序数组啦；此时那个最大值已经踢出堆了，那就再把剩下的堆变成最大堆，堆顶就又是最大值，重复上面的操作即可；文字真的很难懂，还是建议看上面那个视频，对程序员来说没有“墙”这回事吧？ python实现1234567891011121314151617181920212223def heap_sort(arr): def sift_down(start, end): root = start while True: child = 2 * root + 1 if child &gt; end: break if child + 1 &lt;= end and arr[child] &lt; arr[child + 1]: child += 1 if arr[root] &lt; arr[child]: arr[root], arr[child] = arr[child], arr[root] root = child else: break for start in xrange((len(arr) - 2) // 2, -1, -1): sift_down(start, len(arr) - 1) for end in xrange(len(arr) - 1, 0, -1): arr[0], arr[end] = arr[end], arr[0] sift_down(0, end - 1) return arr TODO其实还有其他排序算法的，比如并规排序、希尔排序、二叉树排序等等，以后有机会再总结]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hyperledger Fabric简介]]></title>
    <url>%2F2018%2F07%2F10%2F20180710-Fabric%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[超级账本（Hyperledger）是一个开源区块链的大型项目。它使用区块链技术促进跨行业协作，包括分布式账本框架、身份识别、访问控制和智能合约、客户端库、GUI和实用程序库。 Hyperledger项目于2016年初成立，是Linux基金会的一部分，目前拥有包括IBM在内的50多名成员。我们常听说的Fabric是Hyperledger的五个子项目之一，其他子项目包括Sawtooth、Indy、Burrow 和 Iroha。Fabric是其中最活跃的项目，是一个区块链平台或运行智能合约的基础设施。本篇将从功能特性、应用实例、优势劣势三方面介绍一下Fabric。 功能特性1.身份管理这是Fabric最出名的特性，所有参与者都有已知的身份。区块链在某些项目中无法落地，有一部分原因就是法律规定的参与者都必须有特定的已知的身份。比如私募股权公司或天使投资人，此网络的参与者需要是已知的，而且在资本投资方面具有可信度，然后才能参与区块链。因此Fabric是目前为止在设计上最贴近联盟链思想的区块链，考虑到商业应用对安全、隐私、监管、审计、性能的需求，提高准入门槛，成员必须被许可才能加入网络。 Fabric网络中的不同参与者，都具有封装在X.509数字证书中的数字身份。这些身份确实很重要，因为它们确定了对资源的确切权限以及对参与者在区块链网络中拥有的信息的访问权限。要使身份可以验证，它必须来自可信任的权威机构。会员服务提供商（MSP）是Fabric用于身份验证的一个模块，它是如何实现的？我引用一个官网的例子，机翻见谅： 想象一下，你去超市购买一些杂货。在结账时，您会看到一个标志，表示只接受Visa，Mastercard和AMEX卡。如果您尝试使用其他卡付款 - 我们称之为“ImagineCard” - 无论该卡是否真实且您的帐户中有足够的资金都无关紧要。它不会被接受。拥有有效的信用卡是不够的 - 它也必须被商店接受！ PKI和MSP以相同的方式协同工作 - PKI提供身份列表，MSP说哪些是参与网络的给定组织的成员。PKI证书颁发机构和MSP提供了类似的功能组合。 PKI就像一个卡提供商 - 它分配了许多不同类型的可验证身份。另一方面，MSP类似于商店接受的卡提供商列表，确定哪些身份是商店支付网络的可信成员（参与者）。 MSP将可验证的身份转变为区块链网络的成员。 公钥基础结构（PKI）网络中提供安全通信，和SSL证书原理一样，由权威机构发行证书、有一套机密的加密策略。这里涉及到一个权威机构的参与认证成员，这个在普遍的去中心化思想中好像是不可接收的。但是我个人觉得Fabric应用场景是联盟链，有权威机构的参与反而更容易把区块链技术推向应用市场。 2.模块化Fabric构建于一种模块化架构之上。区块网络主要由两个应用构成：Orderer和Peer，其中Orderer负责交易共识并生成区块，Peer节点负责模拟执行交易和记账。这种划分可以使整个平台拥有更好的弹性和扩展性。Peer和Orderer都是模块化设计，重要模块支持插拔，比如共识机制、合约执行环境、加密算法、证书服务模块等。 模块化设计使得Fabric更像是一个区块链框架，针对不同的服务可以高度定制化，并且类似业务可以复用大部分模块。比如不同的公司对加密算法的要求不同，这个设计就能满足多样性的需求。另外，这种模块化结构是动态可增长的。比如一家管理外汇汇率的公司，有新的规则和标准，甚至添加一家新银行，他们能够以编程方式完成此操作。 3.数据隐私区块链最有可能被应用到金融领域，金融领域对数据的隐私非常注重。许多金融实体表明担忧竞争对手看到所处理的交易数量。一些金融机构没有考虑通过“足够”的加密来保护其数据。 以以太坊为例，ERC20 token的交易的发送方、接收方、交易数量，其实都是透明公开的。如果一个以太坊应用需要上传个人信息，那么只要查到这笔交易，就能找到个人信息的数据，甚至是该应用的所有用户数据。而Fabric 中支持的渠道允许仅将数据传递给需要知道的相关方。 Fabric默认的通道功能可以屏蔽掉不需要看到数据的其他机构。在同一个通道内的节点仍然能够看到全部数据；相同通道内有权限控制机制，简单的讲就是交易可以指定哪些节点需要保存数据，其他节点只会存证hash而不会保存数据。除了区块链系统本身提供的安全机制外，应用程序也可以选择对数据进行加密来保护隐私数据，即记录在链上的数据本身就可以加密保存。 4.智能合约在Fabric中智能合约叫做链码(chaincode)，是上层应用与底层区块链平台交互的媒介。现阶段，Fabric提供Go、Java等语言编写的链码，但不管是哪种语言编写的链码，套路都是差不多的。所有的链码都继承两个接口，init和invoke。init接口用于初始化合约，在整个链码的生命周期里，该接口仅仅执行一次。剩下的invoke接口是编写业务逻辑的唯一入口，虽然只有一个入口，但是可以根据参数传递的不同自由区分不同业务逻辑，灵活性很高。比如应用开发者规定Invoke接口的第一个参数是合约方法名，剩余的Invoke参数列表是传递给该方法的参数，就可以在Invoke接口方法体中根据方法名的不同分流不同业务了。chaincode的API大致可以分为五类： 第一大类与state操作相关。通过这些API可以根据key来查询/添加/更新相应的state。这些API提供了单key的读写操作、key字典序范围读取操作、composite key读取操作、底层数据库语法的查询操作等。 第二大类与与参数相关。需要开发者自己调用API获取传入的参数。 第三大类与交易有关，并且这一类都是读操作，读取transaction中各种信息，比如transaction id、timestamp等。 第四类是与chaincode间相互调用有关的一个API。Fabric允许在一个chaincode中根据chaincode name和channel name去调用另一个chaincode。可以看到并没有deploy的API，也就是说，fabric不允许在一个chaincode中去部署新的chaincode。 最后一类也只有一个API，SetEvent。Fabric允许开发者定义自己的event，然后这个event会在transaction写进block时触发，因此开发者就可以自己写相应的event handler程序做一些相关的工作。 5.多通道模块化里面提到了Orderer和Peer，这里也不得不解释一下。Orderers指提供共识服务的网络节点；Peers指的是维护账本的网络节点。每个Peer节点连接到共识服务的一个或多个通道，就像发布-订阅通信系统中的客户端一样。每个peer节点验证区块并将其提交到账本，然后向应用程序提供其他使用账本的服务。也就是说，在fabric中，一个peer可以参与信息隔离的各种不同的网络，维护特定网络的数据。这一点相比于其他主链的优势在于，其他主链几乎都需要客户端下载所有数据，并且一条主链上包含了所有的应用，网络拥堵、数据冗余的问题在多通道中得以解决。 结论 Hyperledger Fabric是一个许可制区块链的技术平台，旨在为商业化应用所使用。它是开源的，基于工业标准运行用户定义的智能合约，支持强大的安全性身份特征，并且使用具有可插拔共识算法的模块化架构。该架构目前正在发展，并在Hyperledger项目的治理下得到积极开发。 相关链接 Blockchain区块链架构设计 Hyperledger Fabric总论 面向区块链网络的 Hyperledger Fabric 的 6 大技术优势 - IBM Hyperledger &amp; Hyperledger Fabric]]></content>
  </entry>
  <entry>
    <title><![CDATA[以太坊Block Gaslimit动态调整机制分析]]></title>
    <url>%2F2018%2F07%2F02%2F20180702-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%9D%97gas%E4%B8%8A%E9%99%90%E5%8A%A8%E6%80%81%E8%B0%83%E6%95%B4%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[比特币每个区块的大小固定为1M，这使得每个区块所容纳的交易固定，当交易量过大的时候单笔交易的确认时间将会变得非常漫长。以太坊使用了动态调整区块块的gas上限来解决这个问题，让矿工可以投票决定块gas上限为多少。本篇为关于这个机制的一些研究。 动态Gaslimit机制这里讨论的 Gaslimit 是 Block Gaslimit，区别于交易中的Gaslimit，指的是每个块最多可使用的gas。举个例子，现在交易池中有3笔交易，分别消耗 10gas、20gas、30gas，而当前Block Gaslimit为60gas，那么这个块就可以同时打包这三笔交易，并且超过消耗超过60gas的交易会失败；而如果Block Gaslimit 为 50gas，那么最多只能打包其中的两笔交易。Block Gaslimit越大，单个块能包含的交易越多，也就意味着以太坊处理交易的能力（TPS）越强。 Gaslimit在区块链的创世块中就有定义，但是后续可通过矿工的投票来提高区块的gas限制。我们可以在以太坊技术黄皮书 4.3.4章节的公式(47)中找到Block Gaslimit限制的定义。公式比较难排版，简单翻译一下就是： 每个块的Gaslimit可以调整范围为上一个块Gaslimit的正负 1/1024 也就是说，不能一下子把gaslimit提高到很高，需要一个一个块慢慢调整。在geth和parity两个客户端中分别有矿工设置gaslimit的选项：1234# geth--targetgaslimit 3300000# parity--gas-floor-target 3300000 矿工就是靠这两个选项进行投票。需要理解的是，这里设置的是目标gaslimit，因为上面说了共识机制中限制了gaslimit的范围，所以在达到这个目标之前，节点会自动把gaslimit设置到最接近target的数值，直到与目标数值一致。 OK，看完这段一般会有一个疑问，设置高Gaslimit理论上既能打包更多交易，矿工能收取更多交易费，又能提高以太坊处理交易的能力，那为什么矿工们不会一直投票提高Gaslimit？ 为什么需要Gaslimit机制 以及 为什么Gaslimit不会无限高？这个问题其实黄皮书里也没有做具体分析，但是从目前以太坊实际运行情况来看，以太坊的设计者设计Gaslimit的原因可能是多方面的： 这是我查到我认为到最为合理的一个解释。一个块打包的交易越多，意味着区块信息越大，导致该区块传播到整个网络所需要的时间更长；如果每个矿工打包的交易确认时间都很长，那就意味着产生的孤儿块（被抛弃的块）和叔伯块（不被承认但是能获取矿工费的块，以太坊用来降低矿工损失的一种机制）的概率越大，这样不仅减少的矿工的收入，而且因为叔伯块的比例变大，交易费也就越高。 以太坊上运行着智能合约，打包交易不仅包含PoW的计算量，还包含所有交易中的智能合约的运算量，所以一些不太先进的设备发布块的速度会较慢好几秒，这好几秒的延迟可能就导致变成叔伯块了。如果gaslimit无限上升，以太坊的算力又会和比特币一样掌握在少数拥有高级装备的玩家手里。这不符合以太坊的设计初衷。这条我认为也比较靠谱，但可能只是Gaslimit恰好体现出来的好处。 目前没有一个合适的数学算法可以动态计算出Gaslimit应该有的值，所以现在决定权还是放在矿工的手里，以保证灵活性。 相关链接 ethereum yellow paper Uncle Rate and Transaction Fee Analysis StackExchange - How to increase gas limit in block? StactExchange - Why do miners not always “vote” to increase the block gas limit?]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊应用开发学习路径]]></title>
    <url>%2F2018%2F06%2F29%2F20180629-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[想要在以太坊平台上搭建完整的应用除了理论以外需要学习的东西并不算多，这里集中整理一下 搭建一个以太坊客户端以太坊客户端其实就是以太坊节点，在区块链网络中不存在服务器端的概念，所有节点都是对等的客户端。但是去中心化应用（比如以太坊钱包客户端）和以太坊节点之间确实是C/S构架。目前主要流行的客户端有两种，go-ethereum(简称geth)和Parity，其实就是用不同的编程语言完成了相同的逻辑。在以太坊网络中，两种节点是共存的，可以互相连接。目前Parity在各个方面的性能都更加优异，所以之后的项目都会在Parity上，它有如下核心功能： 可以连接不同链的网络同步区块数据，包括：ETH主网络、ETC以太经典、ropsten等开发社区搭建的公有测试网络、本地测试网络、PoA私有链。 提供一个web交互页面，提供主链币和ERC20Token的钱包功能、提供交易监测模块等功能。 可搭建 Proof of Authority（PoA）私有链或者联盟链，区别于使用PoW的以太坊主网络，PoA链不需要挖矿，而是每隔固定时间由指定节点自动产生新的区块 提供RPC/WS/IPC接口，以便各种web应用或者dApp能与Parity交互，发起交易、查看智能合约状态等等 以下是完成这一步骤所需要的相关链接： 我之前写的Parity搭建教程 Parity 官网 Parity github项目地址 Parity 官方英文文档 Parity 发布版下载地址 Parity Gitter 学习使用以太坊客户端的RPC/WS接口这个过程其实就是开发DApp去中心化应用的过程，把以太坊节点当作是应用的数据库，向其请求数据或者发起某个操作。如果你熟悉nodejs，这个过程将会非常简单，只需要掌握两个nodejs的模块就可以完成几乎所有以太坊的操作。其中之一是web3.js,该模块需要通过rpc或者ws连接以太坊客户端才能使用，可以完成查询区块信息、发布合约、发起合约方法调用、发起交易等大量操作。另一个是ethereumjs，里面包含tx、wallet、utils等独立的模块，主要完成了大量不需要以太坊节点就能完成的操作，比如生成钱包地址、加密钱包、签名交易（⚠️签发交易是两个过程，“签”可以本地完成、“发”则需要节点完成）等等。这两个模块都可以通过nodejs的包管理器npm下载。以下是完成这一步骤所需要的相关链接： web3js github地址 web3js 文档 ethereumjs 官网 ethereumjs github地址(每个子模块的README中都包含对应文档) 学习开发Solidity智能合约Solidity是运行在以太坊上的智能合约语言，语法非常少，所以不必担心这个很难学。主要能实现的就是数学计算、调用区块链信息、调用其他合约方法、存储数据等等。需要说明的是Solidity不需要数据库，因为Solidity的变量本身就可以成为数据库。由于区块链的特殊性质，所以调试的过程会比较复杂，我们需要使用一些debuger帮我们完成一部分工作。主要推荐两种： Remix和truffle。Remix是ethereum官方提供的，是一个web界面，直接在浏览器中调试代码，对应的操作也都是界面交互式的，可以使用在线evm，也可以连接你自己搭建的节点或者公共节点。truffle是nodejs的项目，比较推荐用这个，虽然他没有gui，但是功能更强大。truffle可以完成：开发合约、提供evm、编写迁移脚本、编写测试脚本等，组成了完整的开发流程，在开发大型的以太坊项目的时候，往往会发布多个合约共同协同，这时候truffle就体现除了他的价值。完成这一部分所需要的相关链接如下： remix remix测试环境搭建 truffle测试环境搭建 truffle official website truffle docs truffle tutorials 以ERC20为例讲解Solidity编程 ‘开发中能更容易理解理论上的以太坊，关于理论层面的大致说明，我会再写一个文章单独讲解’]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Parity搭建以太坊节点]]></title>
    <url>%2F2018%2F06%2F29%2F20180629-Parity%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[Ethereum目前有两种节点，分别是go-ethereum（简称geth）和Parity。因为Parity出现的时间较晚，解决了geth节点中的许多问题，拥有更好的性能，所以后面所有关于以太坊的讲解都会以Parity环境作为基础。本篇主要说明了Parity节点的搭建和配置。 Parity 安装Parity节点可以被安装在本地或者服务器。有多种方式可以安装，包括编译、Docker、发布版安装文件，并且支持Windows/OS_X/Linux多个系统。关于编译安装和Docker安装，在Parity项目的README文件中有详细说明。这里只说明最简单的安装文件安装。 首先下载对应系统的发布版文件传送门 各个系统上双击下载文件按照提供的界面指引安装 在终端输入parity --version确认安装成功，安装成功输出如下 123456789Parity version Parity/v1.11.4-beta-cc44ae9cb-20180619/x86_64-linux-gnu/rustc1.26.1Copyright 2015, 2016, 2017, 2018 Parity Technologies (UK) LtdLicense GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;.This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.By Wood/Paronyan/Kotewicz/Drwięga/Volf Habermeier/Czaban/Greeff/Gotchac/Redmann 所有parity的相关操作，包括大量配置项，都通过parity这个命令来实现，可通过parity --help查看所有配置项 Parity 参数配置parity的参数配置的具体说明有一个英文文档可以参考。为了方便快速学习，我这里简单说明一下。 两种参数形式第一种是像 parity --help中显示的一样，每个参数都用命令行中的flag表示。如：1parity --chain="ropsten" 表示让parity节点运行在ropsten测试链中。但是这种方式过于繁琐，参数较多的时候不便于管理，所以可以使用第二种toml文件的方式。首先我们要创建一个 config.toml文件，在里面简单写几个配置项：1234567891011121314151617#config.toml[parity]mode = "last"chain = "homestead"light = false[account]unlock = ["0xdeadbeefcafe0000000000000000000000000000"]password = ["/home/user/.safe/password.file"]keys_iterations = 10240[ui]force = falsedisable = falseport = 8180interface = "127.0.0.1"path = "$HOME/.local/share/io.parity.ethereum/signer" toml中的条理比较清晰，将参数所属的不同模块区分开来，比如light参数表示是否使用light模式同步，它属于parity模块的属性，所以写在[parity]下面。toml可以使#来注释。help中的大多数命令行的flag在toml中都有对应的参数（少部分没有），但是参数名称略有不同，这里再提供一个完整的toml文件以供参考：config.full.toml. 该文件中的值即为所有项的默认值，但是偶尔因为版本更替会略有所不同。写好toml文件以后，我们就可以通过如下方法启动parity：1parity --config path/to/config.toml 最常用参数详解本篇目的是快速学习上手，所以就不列举太多，请看下面这个toml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980[parity]mode="active"#这个是parity的同步模式。active表示持续同步区块；passive表示间歇性同步区块；dark表示只有在parity的rpc端口得到命令时才同步区块；last表示使用上次启动时的值chain = "foundation"# 该参数可以让parity节点运行在不同的链上；foundation和mainnet都表示eth主网络；classic表示以太经典；ropsten等是以太坊各种开发社区搞的公有测试练，一般都有对应的水龙头网站可以获取免费的币以供测试。base_path = "./data"# 数据存放位置，区块信息、交易信息等数据文件都会保存在指定的目录下，默认`~/.parity`中，所以为了方便管理，我们让数据生成在指定的文件夹下面light = false# light模式只同步区块头信息，因此能快速同步到最新块，但是正常项目中都需要比较完整的区块信息，所以这里设置成falseno_persistent_txqueue = true# 这个参数和交易有关。节点关闭的时候可能内存中会有部分交易没来得及发出去，如果这里设置成false，下次启动节点的时候还能继续发送这里面的交易；如果设置成true，就丢失了这些交易，需要重新发送。[rpc]# rpc相当于http接口，可通过http请求的形式与parity交互disable = false# 是否关闭rpc接口port = 39842# rpc接口的端口号interface = "local"# rpc接口的ip，local即为localhost/127.0.0.1；也可以设置成0.0.0.0或者节点服务器所ipcors = ["*"]# 设置可访问rpc端口ip列表，设置成*即所有人都能访问apis = ["all"]# 设置开放的api类型，api类型较多，可以以数组的形式传入多个，需要开放所有api时即设置成allhosts = ["all"]# 设置host，host其实是浏览器Host header，一般设置成allserver_threads = 10# 可同时访问的线程数量，这个设置非常有用，在geth中没有这个设置所以容易导致内存不安全[websockets]# websockets是另一种与parity的交互形式，他能提供rpc不能提供的信息，比如能订阅新的交易并收到推送。# 以下内容和rpc一致disable = falseport = 39843interface = "local"origins = ["all"]# 浏览器的origin headerapis = ["all"]hosts = ["all"][ui]parity提供一种web交互的方法，就是这个ui，生成一个网页版的交互界面force = falsedisable = falseport = 39844interface = "all"path = "./data/signer"# 网页需要token来访问，这个是服务器端token的存放地址[network]#parity与其他节点交互的网络设置，比如区块信息的同步就是靠这个网络port = 30303#与其他节点同步用的端口min_peers = 10#最少节点数量，达到这个数量的连接数以后才开始同步并认为同步的信息是正确的；同步的节点越多，就能保证信息越准确；max_peers = 100#最大节点数量，防止连接过多节点导致消耗过多资源 全面的参数信息会通过其他文章来说明。 ParityStartUpToolParityStartUpTool是我写的一个简单的控制工具。其中，start是启动用的shell脚本，就一句代码：12#!/bin/bashparity ui --geth --config="./config.toml" 目前要启动parity的web界面还是需要在命令行中加上ui，如果是在本地的话，会自动启动浏览器。 了解geth的朋友一定会知道如何用web3.js的语法与节点进行交互，但是那是geth上的操作，想让parity也支持这种操作只要在parity中加上--geth，然后用geth attach http://127.0.0.1:8545[rpc端口默认8545]即可，在ParityStartUpTool中有一个attach的脚本能完成这个工作。（rpc端口正常通过http请求就能和节点交互，web3.js简化了这个操作，交互模式变为简单的指令） 同步如果你连上了mainnet或者其中一条公有测试链，那么Parity将需要一些时间来同步，同步后才能进行区块链的所有操作。Parity采用快照模式打包下载大量区块链数据，对已经有大量确认数的历史块不再做校验；当下载高度接近最高块时，才逐个下载数据，大大提高了同步速度。你可以在parity的ui界面，或者geth attach中使用eth.syncing来查看同步状态 相关链接 Parity 官网 https://www.parity.io/ Parity 项目地址 https://github.com/paritytech/parity Parity 官方英文文档 https://wiki.parity.io Parity 发布版下载地址 https://github.com/paritytech/parity/releases “不要用geth当节点”]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>parity</tag>
        <tag>ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[truffle以太坊智能合约开发环境搭建]]></title>
    <url>%2F2018%2F06%2F27%2F20180606-truffle%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[truffle 是以太坊智能合约Solidity编程的IDE之一。 它能在没有搭建geth/parity等以太坊节点的情况下发布并调试合约。在truffle中可以用传统的nodejs测试模块为合约编写测试脚本，并且帮助你省去了 “发布合约-调试合约-重新发布合约” 的麻烦。本篇旨在说明truffle最核心的操作流程，帮助快速上手使用。 安装 npm nodejs我这以前有一篇快速安装教程， 看这里 安装truffle1npm install -g truffle 新建truffle项目官网关于这部分的详细说明在这里我们可以直接创建项目：123mkdir MetaCoincd MetaCointruffle unbox metacoin metacoin是truffle已经存在的一个box，你也可以新建其他box，box其实就是一个可以直接发布的合约模板，包含了项目的源码和测试脚本等文件.你也可以创建一个空的项目：12cd path/to/your/empty/dirtruffle init 这里包括下面为了说明truffle各个功能，我创建了一个名叫TinyCoin的项目，里面会写一个标准的ERC20合约：123mkdir TinyCoincd TinyCointruffle init 完成以后目录会有几文件夹，分别是： contracts 存放合约solidity源码 migrates 存放js写的迁移脚本,帮助你发布合约 test 存放js写的测试脚本 写一个智能合约这里我在contracts文件夹下面写了一个标准的ERC20合约,文件名为TinyCoin.sol：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153pragma solidity ^0.4.18;interface tokenRecipient &#123; function receiveApproval (address _from, uint256 _value, address _token, bytes _extraData) external; &#125;contract TinyCoin &#123; // Public variables of the token string public name; string public symbol; uint8 public decimals = 18; // 18 decimals is the strongly suggested default, avoid changing it uint256 public totalSupply; // This creates an array with all balances mapping (address =&gt; uint256) public balanceOf; mapping (address =&gt; mapping (address =&gt; uint256)) public allowance; // This generates a public event on the blockchain that will notify clients event Transfer(address indexed from, address indexed to, uint256 value); // This notifies clients about the amount burnt event Burn(address indexed from, uint256 value); /** * Constrctor function * * Initializes contract with initial supply tokens to the creator of the contract */ constructor( uint256 initialSupply, string tokenName, string tokenSymbol ) public &#123; totalSupply = initialSupply * 10 ** uint256(decimals); // Update total supply with the decimal amount balanceOf[msg.sender] = totalSupply; // Give the creator all initial tokens name = tokenName; // Set the name for display purposes symbol = tokenSymbol; // Set the symbol for display purposes &#125; /** * Internal transfer, only can be called by this contract */ function _transfer(address _from, address _to, uint _value) internal &#123; // Prevent transfer to 0x0 address. Use burn() instead require(_to != 0x0); // Check if the sender has enough require(balanceOf[_from] &gt;= _value); // Check for overflows require(balanceOf[_to] + _value &gt; balanceOf[_to]); // Save this for an assertion in the future uint previousBalances = balanceOf[_from] + balanceOf[_to]; // Subtract from the sender balanceOf[_from] -= _value; // Add the same to the recipient balanceOf[_to] += _value; emit Transfer(_from, _to, _value); // Asserts are used to use static analysis to find bugs in your code. They should never fail assert(balanceOf[_from] + balanceOf[_to] == previousBalances); &#125; /** * Transfer tokens * * Send `_value` tokens to `_to` from your account * * @param _to The address of the recipient * @param _value the amount to send */ function transfer(address _to, uint256 _value) public &#123; _transfer(msg.sender, _to, _value); &#125; /** * Transfer tokens from other address * * Send `_value` tokens to `_to` in behalf of `_from` * * @param _from The address of the sender * @param _to The address of the recipient * @param _value the amount to send */ function transferFrom(address _from, address _to, uint256 _value) public returns (bool success) &#123; require(_value &lt;= allowance[_from][msg.sender]); // Check allowance allowance[_from][msg.sender] -= _value; _transfer(_from, _to, _value); return true; &#125; /** * Set allowance for other address * * Allows `_spender` to spend no more than `_value` tokens in your behalf * * @param _spender The address authorized to spend * @param _value the max amount they can spend */ function approve(address _spender, uint256 _value) public returns (bool success) &#123; allowance[msg.sender][_spender] = _value; return true; &#125; /** * Set allowance for other address and notify * * Allows `_spender` to spend no more than `_value` tokens in your behalf, and then ping the contract about it * * @param _spender The address authorized to spend * @param _value the max amount they can spend * @param _extraData some extra information to send to the approved contract */ function approveAndCall(address _spender, uint256 _value, bytes _extraData) public returns (bool success) &#123; tokenRecipient spender = tokenRecipient(_spender); if (approve(_spender, _value)) &#123; spender.receiveApproval(msg.sender, _value, this, _extraData); return true; &#125; &#125; /** * Destroy tokens * * Remove `_value` tokens from the system irreversibly * * @param _value the amount of money to burn */ function burn(uint256 _value) public returns (bool success) &#123; require(balanceOf[msg.sender] &gt;= _value); // Check if the sender has enough balanceOf[msg.sender] -= _value; // Subtract from the sender totalSupply -= _value; // Updates totalSupply emit Burn(msg.sender, _value); return true; &#125; /** * Destroy tokens from other account * * Remove `_value` tokens from the system irreversibly on behalf of `_from`. * * @param _from the address of the sender * @param _value the amount of money to burn */ function burnFrom(address _from, uint256 _value) public returns (bool success) &#123; require(balanceOf[_from] &gt;= _value); // Check if the targeted balance is enough require(_value &lt;= allowance[_from][msg.sender]); // Check allowance balanceOf[_from] -= _value; // Subtract from the targeted balance allowance[_from][msg.sender] -= _value; // Subtract from the sender's allowance totalSupply -= _value; // Update totalSupply emit Burn(_from, _value); return true; &#125;&#125; 另外在这个文件夹下面还自带一个migration的合约，是truffle用来做迁移用的，可以暂时不用管 迁移脚本这个内容在官网这里可以查到。在migrates文件夹下面新建一个2_deploy_contracts.js的文件，里面写上发布合约的内容，内容基本是固定的：1234var TinyCoin = artifacts.require("./TinyCoin.sol");module.exports = function(deployer) &#123; deployer.deploy(TinyCoin, 10000, "TinyCoin", "TINY");&#125;; 如果合约需要传参数，像上面一样把无论多少个参数跟在deploy后面就行。我这里是三个参数。官网也给出更多发布合约函数的例子:1234567891011121314151617181920212223242526272829// Deploy a single contract without constructor argumentsdeployer.deploy(A);// Deploy a single contract with constructor argumentsdeployer.deploy(A, arg1, arg2, ...);// Don't deploy this contract if it has already been deployeddeployer.deploy(A, &#123;overwrite: false&#125;);// Set a maximum amount of gas and `from` address for the deploymentdeployer.deploy(A, &#123;gas: 4612388, from: "0x...."&#125;);// Deploy multiple contracts, some with arguments and some without.// This is quicker than writing three `deployer.deploy()` statements as the deployer// can perform the deployment as a single batched request.deployer.deploy([ [A, arg1, arg2, ...], B, [C, arg1]]);// External dependency example://// For this example, our dependency provides an address when we're deploying to the// live network, but not for any other networks like testing and development.// When we're deploying to the live network we want it to use that address, but in// testing and development we need to deploy a version of our own. Instead of writing// a bunch of conditionals, we can simply use the `overwrite` key.deployer.deploy(SomeDependency, &#123;overwrite: false&#125;); 以太坊虚拟机调试环境启动truffle自带的evmtruffle能支持所有evm, 包括geth/parit等等，这里最快最方便的调试方法是truffle自带的evm，你不需要任何安装，并且能完成打包发布等操作,在项目目录下启动：1truffle develop 然后就能进入命令行界面：1234567891011121314151617181920212223242526272829303132Truffle Develop started at http://127.0.0.1:9545/Accounts:(0) 0x627306090abab3a6e1400e9345bc60c78a8bef57(1) 0xf17f52151ebef6c7334fad080c5704d77216b732(2) 0xc5fdf4076b8f3a5357c5e395ab970b5b54098fef(3) 0x821aea9a577a9b44299b9c15c88cf3087f3b5544(4) 0x0d1d4e623d10f9fba5db95830f7d3839406c6af2(5) 0x2932b7a2355d6fecc4b5c0b6bd44cc31df247a2e(6) 0x2191ef87e392377ec08e7c08eb105ef5448eced5(7) 0x0f4f2ac550a1b4e2280d04c21cea7ebd822934b5(8) 0x6330a553fc93768f612722bb8c2ec78ac90b3bbc(9) 0x5aeda56215b167893e80b4fe645ba6d5bab767dePrivate Keys:(0) c87509a1c067bbde78beb793e6fa76530b6382a4c0241e5e4a9ec0a0f44dc0d3(1) ae6ae8e5ccbfb04590405997ee2d52d2b330726137b875053c36d94e974d162f(2) 0dbbe8e4ae425a6d2687f1a7e3ba17bc98c673636790f1b8ad91193c05875ef1(3) c88b703fb08cbea894b6aeff5a544fb92e78a18e19814cd85da83b71f772aa6c(4) 388c684f0ba1ef5017716adb5d21a053ea8e90277d0868337519f97bede61418(5) 659cbb0e2411a44db63778987b1e22153c086a95eb6b18bdf89de078917abc63(6) 82d052c865f5763aad42add438569276c00d3d88a2d062d36b2bae914d58b8c8(7) aa3680d5d48a8283413f7a108367c7299ca73f553735860a87b08f39395618b7(8) 0f62d96d6675f32685bbdb8ac13cda7c23436f63efbb9d07700d8669ff12b7c4(9) 8d5366123cb560bb606379f90a0bfd4769eecc0557f1b362dcae9012b548b1e5Mnemonic: candy maple cake sugar pudding cream honey rich smooth crumble sweet treat⚠️ Important ⚠️ : This mnemonic was created for you by Truffle. It is not secure.Ensure you do not use it on production blockchains, or else you risk losing funds.truffle(develop)&gt; 可以看见在本地测试链上新建了很多帐号以供测试，每个帐号都有一些测试币。在命令行下，可以直接使用javascript和 web3.js的语法（用的web3不到1.0的语法，原因可能是web3 1.0有太多promise，不太适合命令行），比如获取钱包余额：12truffle(develop)&gt; web3.eth.getBalance("0x627306090abab3a6e1400e9345bc60c78a8bef57")BigNumber &#123; s: 1, e: 20, c: [ 1000000 ] &#125; 编译打包智能合约然后就是最重要的,还是在这个命令行下，我们可以用一个命令编译我们刚才写的ERC20合约：1&gt; compile 如果合约有error或者warning，都会在这里显示出来。完成编译后，我们可以看到新增了build文件夹,里面有编译后的json文件。正常编译合约会生成两个文件，或者说字符串，一个是abi（二进制接口），另一个是bin（二进制程序），这里的json文件是truffle整合的一个形式，其实里面包含了abi和bin。 自动发布合约ok，接下来我们刚才写的迁移脚本就起到作用了，我们输入命令来执行迁移脚本：1234567891011121314151617truffle(develop)&gt; migrateUsing network 'develop'.Running migration: 1_initial_migration.js Replacing Migrations... ... 0x9637b2e62481e718f7ad1279bb27c523744303c82a15f23d1c66e5448e6d877d Migrations: 0x8cdaf0cd259887258bc13a92c0a6da92698644c0Saving successful migration to network... ... 0xd7bc86d31bee32fa3988f1c1eabce403a1b5d570340a3a9cdba53a472ee8c956Saving artifacts...Running migration: 2_deploy_contracts.js Replacing TinyCoin... ... 0x0fd1c57e3bee747e5d94568dabd2e1fcd808ca8368f79ddd72238f1d83996948 TinyCoin: 0x345ca3e014aaf5dca488057592ee47305d9b3e10Saving successful migration to network... ... 0xf36163615f41ef7ed8f4a8f192149a0bf633fe1a2398ce001bf44c43dc7bdda0Saving artifacts... 如果你不是第一个使用migrate，需要加个参数把以前的覆盖掉：1&gt; migrate --reset 这样合约就运行在本地链上了,合约地址也显示在上面。 调试合约官方文档相关部分点这里。然后我们用web3的语法发起一个ERC20转账的操作，转账操作会修改合约数据，所以是一个transfer操作（或者叫send操作，相反只查看区块链数据而不需要发起交易的方法叫call）: 123var contract = web3.eth.contract(TinyCoin.abi)var contractInstance = contract.at(TinyCoin.address)contractInstance.transfer(web3.eth.accounts[1],web3.toWei(10), &#123;from:web3.eth.accounts[0]&#125;) 就输出了一个hash值，这个hash就是调用合约transfer方法的交易的hash值，类似这样：10xe57f3608e5696c5cb18ff2690ad88214150072258dc4cb63375e5d3a47eb9909 我们现在有这个交易的hash值了，就可以调试这个已经完成的方法，我们只需要输入：1debug 0xe57f3608e5696c5cb18ff2690ad88214150072258dc4cb63375e5d3a47eb9909 就能看见调试的交互界面123456789101112131415161718192021222324252627truffle(develop)&gt; debug 0xe57f3608e5696c5cb18ff2690ad88214150072258dc4cb63375e5d3a47eb9909Compiling ./contracts/Migrations.sol...Compiling ./contracts/TinyCoin.sol...Gathering transaction data...Addresses affected: 0x345ca3e014aaf5dca488057592ee47305d9b3e10 - TinyCoinCommands:(enter) last command entered (step next)(o) step over, (i) step into, (u) step out, (n) step next(;) step instruction, (p) print instruction, (h) print this help, (q) quit(b) toggle breakpoint, (c) continue until breakpoint(+) add watch expression (`+:&lt;expr&gt;`), (-) remove watch expression (-:&lt;expr&gt;)(?) list existing watch expressions(v) print variables and values, (:) evaluate expression - see `v`TinyCoin.sol:3: interface tokenRecipient &#123; function receiveApproval (address _from, uint256 _value, address _token, bytes _extraData) external; &#125;4:5: contract TinyCoin &#123; ^^^^^^^^^^^^^^^^^^^debug(develop:0xe57f3608...)&gt; 这个界面总是是逐步调试的，可以看到上面的Commands说明里就是这个debug界面的操作方法，比如enter进入调试的下一步，v可以显示当前步骤所有变量的值，还有断点之类的，就不具体说了。 编写测试脚本然后我在test/目录下新建一个tinycoin.js的测试脚本，这里可以使用nodejs传统的mocha测试模块和chai断言库，但是truffle在mocha上又增加了一层，方便针对智能合约的调试。我们看一下这个文件： 1234567891011121314151617181920212223242526272829303132333435var TinyCoin = artifacts.require("./TinyCoin.sol")contract("TinyCoin", function(accounts) &#123; it("should put 10000 tinycoin in the first account", function()&#123; return TinyCoin.deployed().then(function(instance) &#123; return instance.balanceOf.call(accounts[0]); &#125;) .then(balance=&gt;&#123; balance = web3.fromWei(balance) assert.equal( balance, 10000) &#125;) &#125;) it(`should succeed in a transfer * status should be 0x1 * should have a Transfer event with correct output` , ()=&gt;&#123; return TinyCoin.deployed().then( instance=&gt;&#123; return instance.transfer(accounts[1],web3.toWei(10),&#123;from:accounts[0]&#125;) &#125;) .then(ret=&gt;&#123; assert.equal(ret.receipt.status, "0x1", `expect status to be 0x1`) var eventTransfer = null for (var i = 0; i &lt; ret.logs.length; i++) &#123; var log = ret.logs[i]; if(log.event == "Transfer") eventTransfer = log &#125; //should have new event assert(eventTransfer != null, 'except event to be Transfer') //should have correct to,from and value assert.equal(eventTransfer.args.from, accounts[0], `expect from to be account0`) assert.equal(eventTransfer.args.to, accounts[1], `expect to to be account1`) assert.equal(eventTransfer.args.value, web3.toWei(10), `expect value to be 1000`) &#125;) &#125;)&#125;) var TinyCoin = artifacts.require(&quot;./TinyCoin.sol&quot;)哪里都通用，TinyCoin中包含了合约的所有信息（但不是合约实例，合约实例在deployed中） contract(&quot;TinyCoin&quot;, ...mocha的describe在这里被替换成contract， 并且传进来所有帐号accounts方便我们调用合约方法。 下面其中是一个测试样例，用以确认发起合约的帐号中确实存在 10000个 tinyCoin。方法中调用了ERC20的call方法balanceOf，来查询accounts[0]也就是发起合约的帐号中有多少tinycoin的余额。然后用assert验证余额是否和期望值一样。 123456789it("should put 10000 tinycoin in the first account", function()&#123; return TinyCoin.deployed().then(function(instance) &#123; return instance.balanceOf.call(accounts[0]); &#125;) .then(balance=&gt;&#123; balance = web3.fromWei(balance) assert.equal( balance, 10000) &#125;)&#125;) 另一个测试样例中发起了一个token交易，帐号0向帐号1发送了10个tinycoin。在合约中，发起转账会出发一个事件，叫Transfer，Transfer中有三个数据：发送方/接收方/交易数量，因此这里我们还需要验证是否抛出了Transfer以及Transfer中的数据是否正确： 12345for (var i = 0; i &lt; ret.logs.length; i++) &#123; var log = ret.logs[i]; if(log.event == "Transfer") eventTransfer = log&#125; 完成测试脚本以后，我们还是转到刚才的truffle develop的命令行界面，输入test即可开始运行测试脚本，会输出测试结果：12345678910111213truffle(develop)&gt; testUsing network 'develop'. Contract: TinyCoin ✓ should put 10000 tinycoin in the first account ✓ should succeed in a transfer * status should be 0x1 * should have a Transfer event with correct output (41ms) 2 passing (83ms) 总结本篇主要介绍了truffle的核心功能的基本操作，包括编写合约、迁移脚本、搭建测试环境、打包、调试和测试脚本。更多具体功能请参照官网文档，或关注这里的更新 相关链接 truffle official website https://truffleframework.com/ truffle docs https://truffleframework.com/docs truffle tutorials https://truffleframework.com/tutorials web3js docs https://web3js.readthedocs.io/en/1.0/ 本项目github地址 https://github.com/TinyCalf/SmartContracts]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>ethereum</tag>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以ERC20为例讲解Solidity编程]]></title>
    <url>%2F2018%2F05%2F31%2F%E4%BB%A5ERC20%E4%B8%BA%E4%BE%8B%E8%AE%B2%E8%A7%A3Solidity%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[ERC20示例代码以下是一段官方提供的ERC20的代码, 省略了实现部分，完整代码请参考我上传的demo12345678910111213141516171819202122232425262728293031pragma solidity ^0.4.16;contract TokenERC20 &#123; uint256 public totalSupply; mapping (address =&gt; uint256) public balanceOf; mapping (address =&gt; mapping (address =&gt; uint256)) public allowance; event Transfer(address indexed from, address indexed to, uint256 value); event Burn(address indexed from, uint256 value); function TokenERC20( uint256 initialSupply, string tokenName, string tokenSymbol) public function _transfer(address _from, address _to, uint _value) internal function transfer(address _to, uint256 _value) public function transferFrom(address _from, address _to, uint256 _value) public returns (bool success) function approve(address _spender, uint256 _value) public returns (bool success) function approveAndCall(address _spender, uint256 _value, bytes _extraData) public returns (bool success) function burn(uint256 _value) public returns (bool success) function burnFrom(address _from, uint256 _value) public returns (bool success)&#125; 可以从以上的代码中看到ERC20标准的组成元素有这些 totalSupply 总发行量 balanceOf 记录所有地址对应token余额的map allowance 记录地址提取权限的map(ERC20有允许其他地址提取自己token的功能) Transfer 是一个事件，表示产生了本token的交易 Burn 是一个事件，表示销毁了多少token TokenERC20 合约在创建时候的构造函数 _transfer 完成一笔交易的内部函数 transfer 转账给其他地址 transferFrom 从其他地址取出token,前提是有对应的allowance approve 给某个地址提取自己token的权限 burn 销毁token burnFrom 从某个地址中销毁token 后面我会挑一些关键的元素来讲解 ERC20合约解析totalSupply1uint256 public totalSupply; 变量类型这里定义了一个变量 totalSupply，其中 uint256 定义了变量的类型，solidity还包含其他变量，如boolean、address等，详细看 这里. totalSupply是一个可能很大的整数，所以定义为 uint256。 Solidity中没有浮点型的数。 可见性totalSupply 中有public关键字，表示该参数或者函数的可见性，可见性包含 public/private/external/interal 四个关键字，而public的用法和正常语言中的public不太一样。详细可以看这里。 总结起来说，按权限由小到大排序应该是这样 private &lt; internal &lt; external &lt; public private 只能在合约内部被调用 internal 能在合约内部被调用,也能在继承合约中被调用 external 不能在合约内部或继承合约中被调用，除非用this关键字；可以通过合约嵌套或者外部api调用 public 哪里都可以调用 totalSupply功能是让外界知道合约的总发行量，所以使用public关键字，并会默认生成getter，外部可通过getter获取该变量值 balanceOf1mapping (address =&gt; uint256) public balanceOf; 这里有一种新的变量类型，mapping，可以简单的理解为存放键值对的容器，每个地址对应一个token的余额数量，所以以 address -&gt; uint256 来建立这个容器。这里可以通过 balanceOf([某个地址])来获取地址上的余额 TokenERC2012345678910function TokenERC20( uint256 initialSupply, string tokenName, string tokenSymbol ) public &#123; totalSupply = initialSupply * 10 uint256(decimals); // Update total supply with the decimal amount balanceOf[msg.sender] = totalSupply; // Give the creator all initial tokens name = tokenName; // Set the name for display purposes symbol = tokenSymbol; // Set the symbol for display purposes &#125; 和合约名字一样的函数是构造函数，只有在创建合约的时候会被调用，传递的三个值分别是 发行量、token名称、token简称. balanceOf[msg.sender] = totalSupply 这句的功能是给合约发起者所有初始化的token,msg.sender是一个特殊变量，表示该函数调用的发起者，类型是address，还有其他特殊变量，详细可以看这里 _transfer1234567891011121314151617function _transfer(address _from, address _to, uint _value) internal &#123; // Prevent transfer to 0x0 address. Use burn() instead require(_to != 0x0); // Check if the sender has enough require(balanceOf[_from] &gt;= _value); // Check for overflows require(balanceOf[_to] + _value &gt; balanceOf[_to]); // Save this for an assertion in the future uint previousBalances = balanceOf[_from] + balanceOf[_to]; // Subtract from the sender balanceOf[_from] -= _value; // Add the same to the recipient balanceOf[_to] += _value; Transfer(_from, _to, _value); // Asserts are used to use static analysis to find bugs in your code. They should never fail assert(balanceOf[_from] + balanceOf[_to] == previousBalances);&#125; 该函数类型为internal，就像上文说的，这个函数只能在合约内部，或者继承的合约中调用。这个方法处理了token从一个地址转移到另一个地址的简单逻辑错误处理 12345678910require(_to != 0x0);// Check if the sender has enoughrequire(balanceOf[_from] &gt;= _value);// Check for overflowsrequire(balanceOf[_to] + _value &gt; balanceOf[_to]);...// Asserts are used to use static analysis to find bugs in your code. They should never failassert(balanceOf[_from] + balanceOf[_to] == previousBalances); 这个方法用到了require，错误处理方式还有assert和Revert,详见这里 require验证括号内的表达式为false时，方法就会退出，require下方的代码不会执行也不会消耗gas（智能合约中的代码每走一步都需要相应的gas，没用完的gas会退还） assert中一般是不太可能发生的错误，但是一旦发生错误，整个方法调用就会回退，防止严重的漏洞或者错误发生。比如这里用来验证交易后结果是否正确。 事件1Transfer(_from, _to, _value); Transfer是最早定义的一个事件（Event）。Event用来向外部抛出重要的事件，比如这里的转账，这样外部就可以通过Transfer事件来获取所有token的转账信息。以太坊的钱包就是通过Transfer这个事件来确定一笔转账的。 总结ERC20的标准合约目前就用到了这些功能：变量类型、函数、可见性、错误处理和事件。虽然不是Solidity的全部，但是足以用来应对一些简单的功能。更多信息我会在以后讲解其他合约的时候再详细说]]></content>
      <categories>
        <category>Solidity</category>
      </categories>
      <tags>
        <tag>solidity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[siege（围攻）web压力测试工具]]></title>
    <url>%2F2018%2F04%2F12%2Fsiege%EF%BC%88%E5%9B%B4%E6%94%BB%EF%BC%89web%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[Siege是一个轻量级web压力测试脚本，支持POST和GET,能对多个api进行持续性的测试，操作过程简便 官网https://www.joedog.org/ 安装 使用包管理工具安装，比如apt1sudo apt install siege 编译安装12345wget http://www.joedog.org/pub/siege/siege-2.70.tar.gztar zxvf siege-2.70.tar.gz./configuremakesudo make install 常用参数指定并发数量为1001-c 100 指定访问次数为101-r 10 指定访问时间，单位分钟，和指定访问次数不能同时使用1-t 5 指定url文件,保存了所有需要测试的url，后面还会说详细用法1-f apis.txt 从上面的url文件里面随机选择api来测试1-i 指定HTTP头1-H "Content-Type:application/json" 用例仅测试一个url1siege -c 50 -r 5 http://127.0.0.1:3000/v1/getusers 测试一个POST接口，注意最后一个参数是一整个字符串，包含了url和json1siege -H "Content-Type:application/json" -c 1 -r 1 'http://127.0.0.1:1990/v1/submit POST &#123;"user":"tinycalf","pass":"123321"&#125;' 使用文件保存所有url，我们创建一个文件apis，一行一个请求，就像这样12http://127.0.0.1:3000/v1/getusershttp://127.0.0.1:1990/v1/submit POST &#123;"user":"tinycalf","pass":"123321"&#125; 然后如下开始测试1siege -c 50 -r 50 -f ./apis -i -b 就能得到测试结果123456789101112131415** SIEGE 4.0.4** Preparing 50 concurrent users for battle.The server is now under siege...Transactions: 2500 hits Availability: 100.00 %Elapsed time: 0.89 secsData transferred: 3.90 MBResponse time: 0.02 secsTransaction rate: 2808.99 trans/secThroughput: 4.38 MB/secConcurrency: 48.91Successful transactions: 2500Failed transactions: 0Longest transaction: 0.05Shortest transaction: 0.00 Transactions: 总共测试次数 Availability: 成功次数百分比 Elapsed time: 总共耗时多少秒 Data transferred: 总共数据传输 Response time: 等到响应耗时 Transaction rate: 平均每秒处理请求数 Throughput: 吞吐率 Concurrency: 最高并发 Successful transactions: 成功的请求数 Failed transactions: 失败的请求数]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Stress Test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[readline-ui和commander打造node可执行脚本]]></title>
    <url>%2F2018%2F04%2F12%2Freadline%E5%92%8Ccommander%E6%89%93%E9%80%A0node%E5%8F%AF%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[commander可以让你的node脚本像标准可执行文件一样拥有可选参数和帮助界面，readline可以给node脚本增加交互功能 npm项目连接 commander: https://www.npmjs.com/package/commander readline-ui: https://www.npmjs.com/package/readline-ui commander安装1npm install commander --save 用例我就举个最简单的例子，其他具体功能看源项目。 假设我们有一个更改名字的脚本，叫changename12345678#!/usr/bin/env nodevar program = require('commander');program .version('0.0.1') .usage(`-n TinyCalf`) .option('-n, --name [name]', 'your name') .parse(process.argv);console.log(program.name) #!/usr/bin/env node 用来让系统用node来执行这个脚本，这样你只需要用 ./changename来启动脚本，而不需要使用 node changename usage 告诉用户这个脚本该怎么用 option 中规定参数名和描述 通过 program[参数名]就能获取用户输入的参数值 然后我们保存退出，给这个changename增加可执行权限1sudo chmod +x changename 然后就可以执行changename了，我们先运行帮助123456789./changename -h Usage: changename -n TinyCalf Options: -V, --version output the version number -n, --name [name] your name -h, --help output usage information 刚我们设置的用法久都显示出来了，我们再运行带参数的：12./changename -n tinycalftinycalf 成功获取到了name的值 readline-ui安装1npm install --save readline-ui 用例还是刚才的例子，我们给changename加一个用户确认的交互，需要用户输入 Yes！才能记录操作：1234567891011121314151617181920212223242526#!/usr/bin/env nodevar program = require('commander');var UI = require('readline-ui');var ui = new UI();program .version('0.0.1') .usage(`-n TinyCalf`) .option('-n, --name [name]', 'your name') .parse(process.argv);var prompt = `Are you sure to change name to $&#123;program.name&#125;? (Yes!) `;ui.render(prompt);ui.on('keypress', function() &#123; ui.render(prompt + ui.rl.line);&#125;);ui.on('line', function(answer) &#123; ui.render(prompt + answer); ui.end(); ui.rl.pause(); ui.close(); if(answer != "Yes!") process.exit() console.log(`Your name has change to $&#123;program.name&#125;`)&#125;); ui.render 就是发出一个交互，内容为一个字符串 对keypress侦听，将每一个键入的字符连接到交互上，让用户看到自己的输出 line事件就是对回车键的侦听，我们就当作是用户输入完成的信号，然后就可以判断用户输入的是不是 Yes！ 输出大概是这样：123./changename -n tinycalfAre you sure to change name to tinycalf? (Yes!) Yes!Your name has changed to tinycalf]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[合约实现以太坊子钱包]]></title>
    <url>%2F2018%2F04%2F02%2F%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%AD%90%E9%92%B1%E5%8C%85%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[以太坊帐号只有一个地址，不能像比特币一样生成多个地址。通过合约其实可以实现以太坊的子钱包，但我今天开发的可能是一个失败的例子，因为创建合约的成本为355745gas，如果想要这个合约作为中心化应用中的子钱包，1.7CNY一个帐号的负担可能太大了。但是用于个人使用又不想备份太多私钥，却是一个比较好的方法。顺便可以积累一些Solidity的语法和功能 代码部分123456789101112131415161718192021pragma solidity ^0.4.19;contract ERC20 &#123; function transfer(address _to, uint256 _value) public; mapping (address =&gt; uint256) public balanceOf;&#125;contract ChildAccount &#123; address public owner; address public thisaddr=address(this); function ChildAccount () public &#123; owner = msg.sender; &#125; function () payable public &#123; owner.transfer(msg.value); &#125; function withdrawERC20 (address contractAddress) public &#123; ERC20 token = ERC20(contractAddress); token.transfer(owner,token.balanceOf(thisaddr)); &#125;&#125; 代码分析引用其他合约的函数合约中是可以调用其他合约的方法的，前提是你提前申明，就比如我代码里的：1234contract ERC20 &#123; function transfer(address _to, uint256 _value) public; mapping (address =&gt; uint256) public balanceOf;&#125; 由于我在下面用到了ERC20的transfer方法合balanceOf方法，所以我定义了一个ERC20的合约，里面只是按照ERC20的标准申明了这两个函数，并不需要写实现。不写其他申明的原因也是为了解决创建合约的gas。其中transfer是转发ERC20token的方法，balanceOf是查看账户token余额的数组。我在合约ChildAccount的withdrawERC20这个函数中引用了这两个函数：1234function withdrawERC20 (address contractAddress) public &#123; ERC20 token = ERC20(contractAddress); token.transfer(owner,token.balanceOf(thisaddr));&#125; withdrawERC20这个方法用来让主账户提取该合约中的token，用contractAddress合约地址来确定具体是哪个ERC20 token，先获取余额再按余额转账。因为ERC20合约无法直接感知token的进账，所以我们才需要这个函数让主张户主动提取token。当然这边也可以优化，比如可以一次性提取一大批固定的token，甚至可以用一个函数增加支持的token的地址，这里就不再细化了。 自动转账ether上面转账token的方法还是主动调用的方法，但是转账ether可以是完全被动的。就比如payable函数123function () payable public &#123; owner.transfer(msg.value);&#125; 在构造函数中，已经把主张户设置成了owner ： owner = msg.sender，也就是发起合约的账户为主账户。在payable函数中直接把发送来的ether全额打到owner的帐号中。payable在有人向这个合约打ether的时候会主动触发，因此转账过程就完全自动化了。]]></content>
      <categories>
        <category>Solidity</category>
      </categories>
      <tags>
        <tag>Blockchain</tag>
        <tag>geth</tag>
        <tag>Ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器搭建shadowsocks]]></title>
    <url>%2F2018%2F03%2F21%2F%E6%90%AD%E5%BB%BAshadowsocks%2F</url>
    <content type="text"><![CDATA[有的时候像npm apt之类的包管理工具连接不到资源会比较蛋疼。更关键的是程序出了bug不能google怎么办！！！来我们自己做个代理 服务器端搭建我用的是ubuntu服务器，先安装Shadowsocks服务器端123apt-get updateapt-get install -y python-pippip install shadowsocks 此时系统会多出来两个程序：12/usr/bin/ssserver/usr/bin/sslocal 新建一个注册文件，比如ssconfig.json:12345678&#123; "server":"0.0.0.0", "server_port":1999, "local_port":8989, "password":"password", "timeout":600, "method":"aes-256-cfb"&#125; 然后启动sssserver服务 1ssserver -c ./ssconfig.json --log-file /tmp/ss.log -d start 查看ss.log中的记录，确定是否启动成功1tail -f /tmp/ss.log 配置开机自动启动 修改 /etc/rc.local,在exit 0 之前添加以上代码，注意要用绝对路径12345678910111213141516#!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will "exit 0" on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing.ssserver -c /root/ssconfig.json --log-file /tmp/ss.log -d startexit 0 服务器设置完毕 客户端ubuntu/debian安装shadowsocks-libev1sudo apt install shadowsocks-libev 同样要写一个配置文件，不同的是这回ip得改成刚才配置的那台服务器的，写在容易找到的文件夹里面12345678&#123; "server":"the server ip", "server_port":1999, "local_port":8989, "password":"password", "timeout":600, "method":"aes-256-cfb"&#125; 注意有两个端口，server_port是我们刚才配置服务器的ip，local_port是本地ip，也就是本地的各种应用想连vpn要通过的是本地的端口;然后我们开始运行本地ss服务1ss-local -c /path/to/your/ssconfig 后台运行的话这样：1nohup ss-local -c /home/tinycalf/ss/ssconfig &amp; 设置开机自动启动和服务器一样，修改/etc/rc.local12ss-local -c /home/tinycalf/ss/ssconfig &gt; /home/tinycalf/ss/out.logexit 0 如果没有rc.local,直接把以上脚本重新命名，比如sslocal,放到 /etc/init.d下面，再链接到/etc/rc0.d/中即可12cd /etc/rc0.dln sudo ln -s ../init.d/ss-local ./ss-local 如果需要开启全局模式，需要安装polipo1sudo apt-get install polipo 修改polipo的配置文件/etc/polipo/config12345678910logSyslog = truelogFile = /var/log/polipo/polipo.logproxyAddress = "0.0.0.0"socksParentProxy = "127.0.0.1:8989"socksProxyType = socks5chunkHighMark = 50331648objectHighMark = 16384serverMaxSlots = 64serverSlots = 16serverSlots1 = 32 重启polipo来应用变更1sudo service polipo restart 测试是否连接成功12export http_proxy="http://127.0.0.1:8123/"curl ifconfig.me 如果成功就会返回代理服务器的地址而不是本地的地址 其他平台的基本都有界面化工具，输入你的服务器信息就可以了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币山寨币有多好做？看这篇文章的长度就行]]></title>
    <url>%2F2018%2F03%2F20%2F%E6%AF%94%E7%89%B9%E5%B8%81%E6%A0%B8%E5%BF%83%E4%B8%BB%E8%A6%81%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[说实话这篇文章发的有点晚了。直接接触一下代码可能可以从另一个角度去理解比特币的原理，顺便我们还可以创造一下自己的altcoin。 创世块相关Timestamp这里的timestamp就是一句随机的话，表明创建创世块创建的时候发生的某个时间，这句话会被一并加入创世块的哈系算法中。其实只是一个象征意义，在代码里能找到创世块的原文，在Bitcore src/chainparams.cpp的CreateGenesisBlock函数中，原文如下：1const char* pszTimestamp = "The Times 03/Jan/2009 Chancellor on brink of second bailout for banks"; nTime nNonce nBitnTime这个才是我们通常说的linux时间戳，是创世块开采时候的时间，比特核心代码中为1231006505。我们知道比特币挖矿的原理是寻找某个随机数加上一个固定的算法所得出的值的哈系值，如果前n多位是0，那么就可以算是一个新的区块。挖矿就是寻找这个随机数的过程。n越多，难度久越大，这里的nBit其实就代表了创世块的难度，代码中为0x1d00ffff，而真正生成创世块的随机数就是这个nNounce，代码中为2083236893。这三个参数在代码中直接以函数的参数的形式出现，也在src/chainparams.cpp中：1genesis = CreateGenesisBlock(1231006505, 2083236893, 0x1d00ffff, 1, 50 * COIN); 这里的50 * COIN其实没什么用，因为创世块的币是没法用的。每个块的奖励其实不在这里设置，后面再讲。 生成创世块创世块需要两个参数，一个是创世块的hash值hashGenesisBlock，一个是创世块的hashMerkleRoot 。区块链是树状的，需要merkleroot来建立块与块之间的联系。生成创世块我们就需要以上说的 Timestamp,nTime,nBit ,按照指定算法挖矿，得出nNounce,hashMerkleRoot,hashMerkleRoot。有一个python能完成生成创世块的工作，点击这个传送门。得到nNounce,hashMerkleRoot,hashMerkleRoot以后，nNounce还是填入之前的函数参数中，hashMerkleRoot,hashMerkleRoot分别可以在以下代码中找到：12assert(consensus.hashGenesisBlock == uint256S("0x000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f"));assert(genesis.hashMerkleRoot == uint256S("0x4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b")); 共识机制相关SubsidyHalvingInterval这个是减半周期，我们了解比特币4年减半，但是这里的减半周期单位是块，也就是每过210000个块比特币的产出减半。后面我还会回来说为什么是4年。代码是这样的：12// 位置 /src/chainparams.cppconsensus.nSubsidyHalvingInterval = 210000; PowTargetSpacing PowTargetSpacingPowTargetSpacing是目标难度变更时间，源码为2周。PowTargetSpacing是目标出块时间代码中为10分钟。这两个参数相除，就是难度变化周期2016（单位：块）。总结来说，就是每隔2016个块，挖矿难度会重新定义，以此来动态平衡出块时间。举个实际的例子：在前难度周期中，由于矿工算力过大，没有像预期的一样每十分钟出一个块，那么在下一个难度周期中，会按照上一个周期的算力，增加合适的难度，来保证下一个周期中每个块的出块时间大约是十分钟。那么其实我们的初始难度设置低一点也没有太大影响，最终都会按PowTargetSpacing来决定难度。另外，结合上面的减半周期210000和每十分钟出一个块，我们就得出了4年减半的结论。这两个参数的源码如下：123// 位置 /src/chainparams.cppconsensus.nPowTargetTimespan = 14 * 24 * 60 * 60; // two weeksconsensus.nPowTargetSpacing = 10 * 60; Subsidy这个就是挖矿的初始奖励。代码中为50,结合减半周期，每个周期内的的产出为 50 × 2100000，所以总产出为 50 × 2100000 ×（1 + 1/2 + 1/4 + 1/16 + …），积分一下，结果就是2100万。12//位置 /src/main.cppCAmount nSubsidy = 50 * COIN; 其他非重要参数12345// 位置 /src/chainparams.cpppchMessageStart[0] = 0xf9;pchMessageStart[1] = 0xbe;pchMessageStart[2] = 0xb4;pchMessageStart[3] = 0xd9; 这个是网络消息头，用来合其他比特币altcoin区分，随便改其他数字就行123456// 位置 /src/chainparams.cppvSeeds.push_back(CDNSSeedData("bitcoin.sipa.be", "seed.bitcoin.sipa.be", true)); // Pieter Wuille, only supports x1, x5, x9, and xdvSeeds.push_back(CDNSSeedData("bluematt.me", "dnsseed.bluematt.me", true)); // Matt Corallo, only supports x9vSeeds.push_back(CDNSSeedData("dashjr.org", "dnsseed.bitcoin.dashjr.org")); // Luke DashjrvSeeds.push_back(CDNSSeedData("bitcoinstats.com", "seed.bitcoinstats.com", true)); // Christian Decker, supports x1 - xfvSeeds.push_back(CDNSSeedData("bitcoin.jonasschnelli.ch", "seed.bitcoin.jonasschnelli.ch", true)); // Jonas Schnelli, only supports x1, x5, x9, and xd 这个是比特币的初始固定节点，开启比特币时会自动连接，如果你的altcoin一开始没有的话全部注释就行1234// 位置 /src/chainparams.cppbase58Prefixes[PUBKEY_ADDRESS] = std::vector&lt;unsigned char&gt;(1,0);base58Prefixes[SCRIPT_ADDRESS] = std::vector&lt;unsigned char&gt;(1,5);base58Prefixes[SECRET_KEY] = std::vector&lt;unsigned char&gt;(1,128); 这三个参数会影响地址生成的校验位，以区分不同的币种，如果你要做altcoin的最好还是要改。123456789101112131415161718// 位置 /src/chainparams.cppcheckpointData = (CCheckpointData) &#123; &#123; &#123; 11111, uint256S("0x0000000069e244f73d78e8fd29ba2fd2ed618bd6fa2ee92559f542fdb26e7c1d")&#125;, &#123; 33333, uint256S("0x000000002dd5588a74784eaa7ab0507a18ad16a236e7b1ce69f00d7ddfb5d0a6")&#125;, &#123; 74000, uint256S("0x0000000000573993a3c9e41ce34471c079dcf5f52a0e824a81e7f953b8661a20")&#125;, &#123;105000, uint256S("0x00000000000291ce28027faea320c8d2b054b2e0fe44a773f3eefb151d6bdc97")&#125;, &#123;134444, uint256S("0x00000000000005b12ffd4cd315cd34ffd4a594f430ac814c91184a0d42d2b0fe")&#125;, &#123;168000, uint256S("0x000000000000099e61ea72015e79632f216fe6cb33d7899acb35b75c8303b763")&#125;, &#123;193000, uint256S("0x000000000000059f452a5f7340de6682a977387c17010ff6e6c3bd83ca8b1317")&#125;, &#123;210000, uint256S("0x000000000000048b95347e83192f69cf0366076336c639f9b7228e9ba171342e")&#125;, &#123;216116, uint256S("0x00000000000001b4f4b433e81ee46494af945cf96014816a4e2370f11b23df4e")&#125;, &#123;225430, uint256S("0x00000000000001c108384350f74090433e7fcf79a606b8e797f065b130575932")&#125;, &#123;250000, uint256S("0x000000000000003887df1f29024b06fc2200b55f8af8f35453d7be294df2d214")&#125;, &#123;279000, uint256S("0x0000000000000001ae8c72a0b0c301f67e3afca10e819efa9041e458e9bd7e40")&#125;, &#123;295000, uint256S("0x00000000000000004d9b4ef50f0f9d686fd69db2e03af35a100370c64632a983")&#125;, &#125;&#125;; 这个是校验区块链上的固定块是否正确，同样，需要altcoin的话这里注释掉1234567891011121314151617181920// 位置 src/util.cpp#ifdef WIN32 // Windows return GetSpecialFolderPath(CSIDL_APPDATA) / DATA_FILE_NAME;#else fs::path pathRet; char* pszHome = getenv("HOME"); if (pszHome == NULL || strlen(pszHome) == 0) pathRet = fs::path("/"); else pathRet = fs::path(pszHome);#ifdef MAC_OSX // Mac pathRet /= "Library/Application Support"; TryCreateDirectory(pathRet); return pathRet / DATA_FILE_NAME;#else // Unix return pathRet / DATA_FILE_NAME_UNIX;#endif 这里直接把DATA_FILE_NAME和DATA_FILE_NAME_UNIX换成altcoin名字就行，是默认文件夹名称。 完成所以按照整篇文章说的，改掉一些数据，就能很容易自己编译自己的altcoin了，具体编译流程可以参照我以前的比特币文章。但是毕竟，这个技术没什么卵用，自己玩玩就好。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>Bitcoin</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity开发环境搭建及简单合约编写测试]]></title>
    <url>%2F2018%2F03%2F16%2FSolidity%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%AE%80%E5%8D%95%E5%90%88%E7%BA%A6%E7%BC%96%E5%86%99%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[在学习solidity之前，我们先了解下开发和调试的模式 Remix有几种solidity的IDE可供选择，以下我会一直用Remix，一种在线并带有debug的IDE，直接访问网址即可： http://remix.ethereum.org gethgeth是以太坊的客户端，也是以太坊钱包mist的核心。虽然Remix提供了Javascript VM 和 injected web3两种形式可供调试，但是并不能完全满足调试需求。让remix连接本地的geth是一种很好的选择，既可以调试私有链，又可以调试eth的公有链，如果你熟悉geth操作的话，还能减少很多麻烦。 下载gethhttps://geth.ethereum.org/downloads/ 在这个网站上下载1.7.1版本的geth，虽然已经有新的版本更新了，但是有些命令有变动。如果我以后使用1.8版本的话会在这里更新。geth解压以后只有一个可执行文件，名字就叫geth。 启动geth假设我们在私有链中测试合约，我们在geth目录下通过以下命令启动geth以搭建我们的私有链：1./geth --dev --rpc --rpcaddr 127.0.0.1 --rpcport 8545 --rpcapi "personal,db,eth,net,web3,debug" --gasprice "18000000000" --mine --datadir "./data" --rpccorsdomain "*" console 2&gt;&gt;eth.log 简单解释下参数 –dev 私有链测试模式 –rpc 开启rpc端口，以供remix能够访问到 –rpcport rpc端口，默认其实就是 –rpcapi 开放哪些rpc接口，尤其是debug，remix会需要用到这个 –mine 自动挖矿 –gasprice gas的价格，如果不设置测试环境中就为0,那就和共有链不一样了，导致测试结果偏差 –datadir 区块链资源存放的位置，最好设置一下不然很难找，如果你想删除所有区块链信息和钱包重启私有链，删除这个文件夹就行 终端中启动完geth就放在那就行了，现在我们去remix里面，在右上角的run选项卡里找到Environment，选择web3 provider,如下图 因为我们默认端口是8545,所以提示输入本地接口地址的时候什么都不用变，点确定就行。如果连接成功会有提示。 关于帐号再进入下一步之前，我们要现在geth中创建一个账户，不然没法完成测试。关于geth的其他操作我在其他文章里会讲，这里只是提一下会用到的命令。打开刚才启动geth的终端，输入以下命令： 创建帐号1personal.newAccount("password") 反复使用创建多个帐号 解锁帐号1personal.unlockAccount(eth.accounts[0],"password",100000000) 最后一个数字写大一点，是解锁的时间，以免remix经常提示帐号没解锁 批量解锁帐号1234var pass = "password"for(var i=0;i &lt; eth.accounts.length ; i++) &#123; personal.unlockAccount(eth.accounts[i],pass,100000000)&#125; 我们经常需要多个帐号调试，所以这里提供一个批量解锁帐号的方法，直接输入到geth终端即可 编写并创建一个简单合约ok，我们可以正式开始创建合约了。我从官网找了一段ERC20合约的示例代码过来，如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153pragma solidity ^0.4.16;interface tokenRecipient &#123; function receiveApproval(address _from, uint256 _value, address _token, bytes _extraData) public; &#125;contract TokenERC20 &#123; // Public variables of the token string public name; string public symbol; uint8 public decimals = 18; // 18 decimals is the strongly suggested default, avoid changing it uint256 public totalSupply; // This creates an array with all balances mapping (address =&gt; uint256) public balanceOf; mapping (address =&gt; mapping (address =&gt; uint256)) public allowance; // This generates a public event on the blockchain that will notify clients event Transfer(address indexed from, address indexed to, uint256 value); // This notifies clients about the amount burnt event Burn(address indexed from, uint256 value); /** * Constrctor function * * Initializes contract with initial supply tokens to the creator of the contract */ function TokenERC20( uint256 initialSupply, string tokenName, string tokenSymbol ) public &#123; totalSupply = initialSupply * 10 ** uint256(decimals); // Update total supply with the decimal amount balanceOf[msg.sender] = totalSupply; // Give the creator all initial tokens name = tokenName; // Set the name for display purposes symbol = tokenSymbol; // Set the symbol for display purposes &#125; /** * Internal transfer, only can be called by this contract */ function _transfer(address _from, address _to, uint _value) internal &#123; // Prevent transfer to 0x0 address. Use burn() instead require(_to != 0x0); // Check if the sender has enough require(balanceOf[_from] &gt;= _value); // Check for overflows require(balanceOf[_to] + _value &gt; balanceOf[_to]); // Save this for an assertion in the future uint previousBalances = balanceOf[_from] + balanceOf[_to]; // Subtract from the sender balanceOf[_from] -= _value; // Add the same to the recipient balanceOf[_to] += _value; Transfer(_from, _to, _value); // Asserts are used to use static analysis to find bugs in your code. They should never fail assert(balanceOf[_from] + balanceOf[_to] == previousBalances); &#125; /** * Transfer tokens * * Send `_value` tokens to `_to` from your account * * @param _to The address of the recipient * @param _value the amount to send */ function transfer(address _to, uint256 _value) public &#123; _transfer(msg.sender, _to, _value); &#125; /** * Transfer tokens from other address * * Send `_value` tokens to `_to` in behalf of `_from` * * @param _from The address of the sender * @param _to The address of the recipient * @param _value the amount to send */ function transferFrom(address _from, address _to, uint256 _value) public returns (bool success) &#123; require(_value &lt;= allowance[_from][msg.sender]); // Check allowance allowance[_from][msg.sender] -= _value; _transfer(_from, _to, _value); return true; &#125; /** * Set allowance for other address * * Allows `_spender` to spend no more than `_value` tokens in your behalf * * @param _spender The address authorized to spend * @param _value the max amount they can spend */ function approve(address _spender, uint256 _value) public returns (bool success) &#123; allowance[msg.sender][_spender] = _value; return true; &#125; /** * Set allowance for other address and notify * * Allows `_spender` to spend no more than `_value` tokens in your behalf, and then ping the contract about it * * @param _spender The address authorized to spend * @param _value the max amount they can spend * @param _extraData some extra information to send to the approved contract */ function approveAndCall(address _spender, uint256 _value, bytes _extraData) public returns (bool success) &#123; tokenRecipient spender = tokenRecipient(_spender); if (approve(_spender, _value)) &#123; spender.receiveApproval(msg.sender, _value, this, _extraData); return true; &#125; &#125; /** * Destroy tokens * * Remove `_value` tokens from the system irreversibly * * @param _value the amount of money to burn */ function burn(uint256 _value) public returns (bool success) &#123; require(balanceOf[msg.sender] &gt;= _value); // Check if the sender has enough balanceOf[msg.sender] -= _value; // Subtract from the sender totalSupply -= _value; // Updates totalSupply Burn(msg.sender, _value); return true; &#125; /** * Destroy tokens from other account * * Remove `_value` tokens from the system irreversibly on behalf of `_from`. * * @param _from the address of the sender * @param _value the amount of money to burn */ function burnFrom(address _from, uint256 _value) public returns (bool success) &#123; require(balanceOf[_from] &gt;= _value); // Check if the targeted balance is enough require(_value &lt;= allowance[_from][msg.sender]); // Check allowance balanceOf[_from] -= _value; // Subtract from the targeted balance allowance[_from][msg.sender] -= _value; // Subtract from the sender&apos;s allowance totalSupply -= _value; // Update totalSupply Burn(_from, _value); return true; &#125;&#125; 好了，我们现在还不需要直到合约里面到底写了什么，我们只要把这段代码复制到Remix中就可以了。然后选择Compile选项卡，点击 start to compile。没有错误就切换到run选项卡，在create中填入ERC20合约的三个参数，分别是发行量、token名字、token简称，像这样：1100000,"TinyCalf Token","TCT" 在address中复制上面的帐号地址下来，点击create。左下角会提示pending，等挖矿，下一个块生成后，合约就创建成功了。如图 点击下面的各种函数的按钮就可以完成合约函数的调用 调试合约交易我们点击下面的tototalSupply,symbol,name这些方法，可以直接显示结果，因为这些函数调用只需查看区块链就能实现。而很多方法需要通过向合约发送数据才能实现，比如transfer方法，就是把一个帐号中的token发到另一个帐号，这个过程相当于我要告诉合约，我要转给B一些token，合约来记录这个过程，所以这个方法相当于发给合约的一个交易，将调用什么方法，需要哪些参数告诉了合约。我这里阐述得简单一点，大概懂就行，具体的我会在其他文章里讲。回到正题，transfer需要两个参数，目标地址和数量，我们在transfer的输入框中输入：1"0xfc9f5c897eda12d1131ecd7b7db2fa67fb28c24c","1000000000" 记得把地址改成你创建的另一个，点击transfer，这时后又会显示pending，正如我所说，这个方法本身是一个交易。等到新块生成，交易确认以后，我们就可以在左边的输出框中点debug来调试这笔交易，如图这个操作界面我就不多说了，还是比较简单明了的，能逐步运行函数，检查每个变量的值。 简单解释下合约的原理有一点需要明确，合约不是在区块链中执行的，而是在每个节点本地执行的。区块链上记录的是什么帐号调用了什么方法。本地执行了合约从创建开始到现在，所有区块链上记录的函数调用，以得出一个最终的状态。合约地址本身是一个没有人直到私钥的帐号，可以接收toke和ether。token是合约的一个应用，传递token只是一个合约方法，原理是告诉合约A要转给B多少个token，合约里面记录了每个地址的token数量，和ether的原理不一样。有问题的直接留言，本篇结束。]]></content>
      <categories>
        <category>Solidity</category>
      </categories>
      <tags>
        <tag>Blockchain</tag>
        <tag>geth</tag>
        <tag>Ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GETH客户端基本操作]]></title>
    <url>%2F2018%2F02%2F01%2FGETH%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[我写的肯定没有文档全，但是文档太多了，刚看的童鞋肯定一脸蒙B，所以我整理了一下开发以来最常用到的操作，希望大家能少踩些坑 准备工作 geth，全名go-ethereum，git项目地址：https://github.com/ethereum/go-ethereum 命令行的API可以参考这个 https://github.com/ethereum/go-ethereum/wiki/Management-APIs web3,即javascript的API，使用方法看 https://github.com/ethereum/wiki/wiki/JavaScript-API#web3ethgetbalance geth下载地址 https://geth.ethereum.org/downloads/ 启动geth没错，客户端下载下来就一个geth文件，有三种方法可以启动，按自己的需要来 带前端交互的启动这种启动方式可以通过命令行直接控制钱包，但是退出进程后客户端也不会再后台运行12cd path/to/geth/./geth console 2&gt;&gt;eth.log 效果应该是这样的12345678910$./geth console 2&gt;&gt;eth.logWelcome to the Geth JavaScript console!instance: Geth/v1.7.2-stable-1db4ecdc/linux-amd64/go1.9coinbase: 0x6847aee3f59652e3ddc51087416360f17ab9c8b1at block: 0 (Thu, 01 Jan 1970 08:00:00 CST) datadir: /home/jonathan/Desktop/Coinnodes/ETH-1.7.2/data modules: admin:1.0 debug:1.0 eth:1.0 miner:1.0 net:1.0 personal:1.0 rpc:1.0 txpool:1.0 web3:1.0&gt; &gt;后面可以输入命令，这个我们后面会讲。当然启动的时候有一些比较叫重要的参数有必要讲一下，我常用的启动脚本是这样的：1./geth --rpc --rpcaddr 127.0.0.1 --port 10071 --rpcport 10070 --rpcapi "personal,db,eth,net,web3" --datadir "./data" console 2&gt;&gt;eth.log --rpc 表示启用rpc端口 --rpcaddr rpc端口的地址 --rpcport rpc所在端口 --rpcapi 规定rpc可访问的命令范围，有personal,db,eth,net,web3等，用逗号隔开 --port geth节点p2p的端口 --datadir 规定本地数据库，区块链存储，以及私钥等存放的地址，默认地址 ～/.ethereum --dev 加上这个参数则会启动私有链 写成shell脚本效果更佳～ 前后端分离的启动这种方式既可以随时和geth交互，又不影响geth在后台运行，在服务器上非常有必要。先用nohup在后台进程中跑geth1nohup ./geth --datadir "./data" &amp; 然后使用attach命令开启交互界面1./geth attach ipc:./data/geth.ipc geth启动时会在我们规定的data目录生成ipc，但是这个ipc因为版本的不同可能出现在不同的位置，找一下就好，我们把attach的地址设置成该ipc所在地址，即可再次进入交互界面，用exit退出也不会影响后台进程。 同步以下所有命令在geth的console中输入即可 查看同步状态1eth.syncing 这个命令会返回false或者一个同步状态的数组;有两种情况会返回false，一是还没找到任何节点，并且没有开始同步，二是找到节点了并且已经同步到最高块;如果返回数组则表示正在同步，并输出最高块和当前同步的块高 查看当前同步高度12&gt;eth.blockNumber5220670 查看节点数量看看当前是不是已经连上其他节点了12&gt; net.peerCount5 查看当前同步节点的详细信息1234567891011121314151617181920212223242526272829303132&gt;admin.peers[&#123; caps: ["eth/62", "eth/63", "par/1", "par/2", "pip/1"], id: "3148c38ffb1b5328cfd121653cc70ec68a44390d68e304d3fa8b09fcf6a28e9b13e5125332ad8da194ce740eaf011daa6f36dfee43a3a2f43e067776928876ea", name: "Parity/v1.7.8-unstable-d5fcf3b-20171025/x86_64-linux-gnu/rustc1.19.0", network: &#123; localAddress: "172.31.32.9:46758", remoteAddress: "45.56.113.50:30304" &#125;, protocols: &#123; eth: &#123; difficulty: 205043033534245860000, head: "0x5b1ac93fc624387d6805d350284ec5faa71f61a463babfd1086771085bf0a4b1", version: 63 &#125; &#125;&#125;, &#123; caps: ["eth/62", "eth/63", "par/1", "par/2", "pip/1"], id: "cef80e2721f25ae6468f5f3db3ed05a7ea6b3278b8c9acd1afc103508eaf3e2d56846eac5854b9e18bad99b61d1301850ca01e126df4df63804af899565f6570", name: "Parity/v1.8.2-unstable-1b6588c-20171025/x86_64-linux-gnu/rustc1.20.0", network: &#123; localAddress: "172.31.32.9:20368", remoteAddress: "217.182.90.254:30303" &#125;, protocols: &#123; eth: &#123; difficulty: 205043033534245860000, head: "0x5b1ac93fc624387d6805d350284ec5faa71f61a463babfd1086771085bf0a4b1", version: 63 &#125; &#125;&#125;] 增加节点以太坊经常会出现半天都找不到节点的情况，我们需要手动添加一些节点，比如12&gt;admin.addPeer("enode://20c9ad97c081d63397d7b685a412227a40e23c8bdc6688c6f37e97cfbc22d2b4d1db1510d8f61e6a8866ad7f0e17c02b14182d37ea7c3c8b9c2683aeb6b733a1@52.169.14.227:30303")true 类似括号中的节点信息可以百度找一些。 账户创建账户1personal.newAccount([你的密码]) 查看所有帐号以太坊和比特币不同，比特币客户端只支持一个账户，一个账户下可生成无限地址;而以太坊能支持无限个账户，但是每个账户都只有一个地址，我们可以这样查看所有帐号：12&gt; eth.accounts["0x6847aee3f59652e3ddc51087416360f17ab9c8b1"] 输出结果就是我们刚创建的帐号，如果我们创建更多,就会这样:12&gt; eth.accounts["0x6847aee3f59652e3ddc51087416360f17ab9c8b1", "0xa9ee089a9a8837bfd0b232198e5850ba94ca4ab4"] 我们可以用javascript的语法获取其中某个地址12&gt; eth.accounts[0]0x6847aee3f59652e3ddc51087416360f17ab9c8b1 解锁帐号所有转出的操作之前必须先解锁帐号。比如我们想解锁帐号0:12&gt; personal.unlockAccount(eth.accounts[0],"PASSWORD",1000000)true 参数依次是 帐号/密码/时间（毫秒） 挖矿在测试网络中我们需要挖矿来获取ether,另外要保证已经创建过帐号才能进行挖矿。 开始1miner.start(1) 括号里的数字表示进程数，不写会默认占用你所有cpu资源。挖矿得到的ether会自动打到第一个账户中。 停止1miner.stop() 结合上面的”查看当前同步高度“可以看看挖了多少 资金查看账户余额我们在测试网中挖到矿以后，就可以查看下余额123var ac = eth.accounts[0]var balance = eth.getBalance(ac)web3.fromWei(balance) 输出1320 其中fromWei是web3提供的单位转换操作，关于类似操作下面还会提到 转账我们以测试网络中帐号0转100个ETH给帐号1为例子,需要结合上面的解锁账户功能：123456789var from = eth.accounts[0]var to = eth.accounts[1]var amount = 100personal.unlockAccount(from,"PASSWORD",100000)eth.sendTransaction(&#123; from:from, to:to, value:web3.toWei(amount),&#125;) 这个命令中我们只需要修改一开始定义的 from（发送帐号）/to（目标帐号）/amount（数量）即可;另外我们还是使用了web3.toWei来转换单位。但是实际中使用会相对复杂一些，比如你需要提取一个账户中所有的余额，那你就需要计算一下需要多少矿工费，并扣除矿工费转出：1234567891011121314var from = eth.accounts[0]var to = eth.accounts[1]personal.unlockAccount(from,"PASSWORD",100000)tx=&#123; from:from, to:to, value:eth.getBalance(from)&#125;var gasPrice=eth.gasPrice;var gas=eth.estimateGas(tx);tx.gasPrice=gasPrice;tx.gas=gas;tx.value=web3.toBigNumber(tx.value).minus(gasPrice*gas);eth.sendTransaction(tx) 这个操作中我们先定义了tx，假设发送数量为所有余额，这样我们就能通过estimateGas来计算所需要的gas，实际的矿工费为gasPrice * gas(单位ether);然后我们再在value中减去需要的矿工费，构成一笔交易单tx，使用sendTransaction将其广播。这里面的加减法我们用了web3中的bignumber类，下面会详细说明;另外测试环境记得挖矿才能完成交易的操作 数学运算fromWei 和 toWeiether的最好单位是Wei，Wei不可分割，geth中所有关于金额的操作使用的单位都是Wei，于是就有了fromWei和toWei来转换单位;比如我们getBalance获取的余额单位是Wei难以阅读：12&gt; web3.fromWei("123499999999999999800")"123.4999999999999998" 或者12&gt; web3.fromWei("123499999999999999800","ether")"123.4999999999999998" 再比如我们想发送100个ether，那transaction中的value就应该是：12&gt; web3.toWei("100")"100000000000000000000" bigNumberether最多可以有18位小数，js本身无法进行相应计算，比如我们在node或者geth中输入：12&gt; 123499999999999999800-0123500000000000000000 明显发生了计算错误，所以就像我在转账中写的，所有数学计算前都要转换成bignumber，并使用bignumber的计算方法计算12&gt; web3.toBigNumber("123499999999999999800").minus(1)123499999999999999799 记得toBigNumber中的参数是String 总结我这里只写了geth客户端中最基本最常用的命令，为了读者们能快速上手。由于geth客户端的交互使用的js脚本，因此操作非常灵活，我们可以根据自己的业务需求编写各种控制脚本。想用nodejs通过外部RPC控制geth的话，你需要通过npm下载web3的模块;官方提供的web3中不包含personal/miner/admin，所以可能需要使用非官方的web3_extended。以后可能会写个有关token的操作，因为那部分也比较复杂。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>ethereum</tag>
        <tag>以太坊</tag>
        <tag>ETH</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EOS简介--区块链操作系统]]></title>
    <url>%2F2017%2F09%2F21%2FEOS_Intro%2F</url>
    <content type="text"><![CDATA[本篇为steemit论坛的英文文章搬运,翻译自@trogdor的 Introduction to EOS: the Epic (blockchain) Operating System，原文为地址为: https://steemit.com/eos/@trogdor/introduction-to-eos-the-epic-blockchain-operating-system EOS：共识机制下的史诗级、企业级块链操作系统EOS是一个区块链操作系统，它提供了数据库，账号许可，调度，认证和互联网应用通信，这极大地提高了智能商业开发的效率，它使用了并行计算使得把区块链拓展到百万用户和每秒百万次交易成为可能。为了介绍EOS，我们首先需要理解现在区块链技术的情况，并且知道我们是怎么走到现在的。比特币引入了公共账本系统的概念，以太坊证明了对去中心化应用的需求的普遍性。然而，为了看到区块链真正的成为主流，我们必须能处理现实世界中的交易需求。比如，信用卡网络需要能在每秒内处理20,000笔交易。facebook要每秒处理52,000笔交易，这还不包括post和其它行为。金融行业每秒处理100,000交易。而比特币由于区块大小的限制，目前每秒只能处理大约3笔交易，以太坊由于燃料(gas)限制，每秒只能处理30笔交易。目前区块链技术最重要的限制是单线程的性能。 我们是如何走到今天的2013年，去中心化交易所bts创建，2014年发布。它使用代理pos方式，只需3秒确认。bts的第一版的部分理念和技术来自比特币，但是这依然无法达到一个交易所对性能的要求。2015年我们开发了石墨烯系统，完全重写了bts。这使得一台机器能每秒处理100000笔交易，并且在全球压力测试中达到了每秒18000笔交易。用户名系统也与bts一同发布，这就把用户名与密钥区分开来，使得企业组织能被其它使用者组织批准审核。2016年发布了steem，steem使用了一些新的概念。社交媒体用户不想每次投票都要支付，他们想要账号的恢复等等。steem还把原本浪费在挖矿的回报重新分发给在区块链上发问的人，使得成千上万的人参与了进来。此时，每天在steem和bts上的真实交易超过了其它主要区块链的总和。steem上的男女用户比也超过了其它区块链。然而，steem和bts还是应用型区块链。如果你想在一个区块链上运行多个app，还需要解决拓展性问题。 距离主流社会接受区块链还有明显的障碍如果你看看现在的区块链行业，你会发现每个人都想建立智能商业，去中心化组织等等，在此过程中，开发者必须从零开始搭建去中心计算机来运行他们的智能app。由此，所有的app开发者都必须去解决相同的问题：账户系统，恢复过程，等等等等，其实他们缺少的是一个操作系统，由操作系统提供每个应用都需要的通用功能，这样这些应用就能专注于他们自己的业务逻辑。举个例子，bts和steem之间在功能上十分类似，只是在业务逻辑上有些许差别。EOS的目标是提供一个操作系统，此操作系统提供了所有核心的功能，app开发者只需要专注于自己的业务逻辑即可。 DAPP需要什么？为了成功，DAPP必须能从浏览器访问（当然，可下载的app模式也可以），能拓展百万用户以获取回报，对于app的用户应当免费（尤其是社交媒体用户），应能快速确认，能升级，能用用户友好的用户名登陆，能恢复账户，还能修复bug。EOS为开发者提供了所有这些功能。EOS为智能合约提供了并行处理，异步通信等功能。将提供了数据库，账号许可，调度，认证和互联网应用通信功能。比如，bts和steem可以在EOS上并行运行，而由于异步通信，多余的节点和整个簇都能在交易处理的后台运行。EOS是第一个区块链操作系统。它为你的应用提供了数据库，schema，管理数据的多种维度。提供账号许可系统，账号恢复系统，处理多任务，处理认证以及密钥管理，因此，你可以专注与业务逻辑而不是密码学，EOS还负责处理所有的互联网应用通信。EOS使得我们能专注与构建app，使得我们的用户不需要强制性的燃料，不需要在使用前做别的事情，它使得开发者能快速地构建app，我们对此翘首期盼。 EOS旨在扩展性，灵活性和可用性扩展性：EOS通过并行执行和异步通信可支持1000个商业级的dapp。它把认证从行为(action)中分离。举例来说，交易就是减少一个账户的余额，然后增加另一个账户的余额的行为，但是所有的认证步骤都在验证签名，确保其有充足的资金，等等，但是认证步骤其实只需要在区块产生时执行一次即可。区块在被添加到区块链之后，你不需要在去认证一次。EOS把源码放到区块链上，使得智能合约的内容对于用户来说是可读的，每个人都能浏览它都内容，开发者可以优化它，并在不同都机器上编译。同样，一些额外的重要的操作也不需要燃料。灵活性：由于EOS将使用pos机制，如果一个app失败了，选举的区块生产者可以冻结此app，直到修复了bug并升级代码。因此，如果用EOS来实现DAO，它就可以被冻结，修复和升级，而不用硬分叉或中断链上的其它应用。在EOS上，你也可以只运行你需要的app。如果你想运行一个交易所app，那么你不需要运行社交媒体app，此时你的本地节点只需要处理那些你关心的数据即可。不是每个节点都需要运行与保存区块链的所有状态。EOS会公开源码，提供通用的基于角色的许可机制。可用性：EOS将提供一个web工具包用于界面开发，自描述的界面，自描述的数据库schema。治理：pos机制选举块生产者。一个合法的宪法(constitution)建立一个解决争端的司法。EOS将包括一个自组织的社区，社区通过投票产生。每个账号都要签署宪法（constitution）。这其中的一个想法是每笔交易可能会包含当前宪法的状态的哈希值。宪法本身是能被修改和演化的，并包含了区块链试图表达的意图，以及引导解决争端的方向。 EOS代币EOS有一个代币：EOS，它的运作原理与steem相同。与其它系统不同的是，它免费，它不会被消耗。如果你拥有网络的1%，那么你就拥有1%的计算能力，1%的带宽，1%的网络存储。你可以把它出租给其它人或者用在你自己的app上。如果你为你的app筹集到了足够的EOS来支撑它的使用，你无需担心需要支付费用，因为，它是“拥有”模式，而不是“出租”模式。网络带宽可以通过一个自由市场生态系统分配。区块的生产由投票控制，就像传统的pos机制那样。EOS的供应会分配为三种不同的智能合约，这些将由投票决定。多余的供应会被销毁，只需要在智能合约中锁定它们即可，这可以防止它们被使用（消除通胀），或者它们可以被用于去中心化的治理（比如steem），或者中心化的治理（比如以太坊基金，EOS基金）。 当前开发团队Brendan Blumer：CEODaniel Larimer：CTOKokuei（Guo）Yuan：总裁Andrew Bliss：CFOMichael Cao：合伙人Ian Grigg：合伙人Brock Pierce：合伙人李晓莱：合伙人Wendy Lee：CLOBo Shen：合伙人]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>Blockchain</tag>
        <tag>EOS</tag>
        <tag>Bitshare</tag>
        <tag>Graphene</tag>
        <tag>比特股</tag>
        <tag>石墨烯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node+nginx配置ssl证书]]></title>
    <url>%2F2017%2F09%2F09%2Fnode%2Bnginx%E6%90%AD%E5%BB%BASSL%2F</url>
    <content type="text"><![CDATA[本节记录一下node.js项目如何配合nginx配置ssl证书，主要用来解决copay的iOS客户端链接bws时出现的BADREQUEST问题，顺便优化一下url copay客户端问题在我们之前修改好的copay项目已经链接到山寨币的情况下，启动iOS工程以后服务器端会出现如下报错： 1BADREQUEST Required argument name missing 导致客户端无法创建钱包、无法生成地址。原因在copay的github讨论中有涉及到：https://github.com/bitpay/bitcore-wallet-service/issues/628这个问题目前只出现在了ios上，原因是域名没有ssl证书，下载或者申请一个，用nginx解析一下即可 申请并下载ssl证书阿里云可以申请免费的证书，或者去其他地方申请，下载后应该有两个文件。 12xxxx.pemxxxx.key 最好申请两个证书，一个给insight，一个给bws，并接解析两个域名，比如我的insight网址和bws接口地址：https://blockchain.browser.tiny-calf.com/insight/https://bws.tiny-calf.com/bws/api正常ssl证书可以分配多个域名的，并且可以使用通配符，但是阿里的免费证书只支持一个耳机域名，所以要申请两个。 安装配置nginx安装1apt install nginx-core 上传证书完成后应该自动启动了，然后进入 /etc/nginx/ 并创建一个文件夹把我们刚下载的证书放进去,比如我创建的是cert文件夹：12cd /etc/nginx/mkdir cert 配置新的虚拟主机回到上级目录我们查看以下 nginx.conf 其中引用的两个文件夹的配置文件12include /etc/nginx/conf.d/*.conf;include /etc/nginx/sites-enabled/*; 说明我们需要在 sites-enabled 中添加虚拟主机，但是 sites-enabled 下实际上是 sites-available 中文件的链接，所以我们实际上实在 sites-available 中创建新的虚拟主机的配置文件，然后在把需要用的文件链接到 sites-enabled 。OK，那来吧。进入 sites-enabled有个 default 文件，复制两个出来，分别命名为 insight 和 bws，然后两个文件的配置其实是差不多的，我拿insight文件作为例子：123456789101112131415161718192021222324252627282930server &#123; listen 80; #替换成你的域名 server_name blockchain.browser.tiny-calf.com; #将http请求强制转到https rewrite ^/(.*) https://blockchain.browser.tiny-calf.com/$1 permanent;&#125;server &#123; ssl on; #换成你的证书名称 ssl_certificate cert/xxxxxxxx.pem; ssl_certificate_key cert/xxxxxxxx.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; index index.html index.htm index.nginx-debian.html; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; #insight的nodejs端口为3001,因此这里吧请求全转到3001端口 proxy_pass http://127.0.0.1:3001; proxy_redirect off; &#125;&#125; 重要配置看注释，然后 bws 也是一样，bws 的端口号为3232,记得换一下。然后我们把 bws 和 insight 连接到 sites-enabled 并删除原来 default 的链接1234cd sites-enabledsudo rm defaultsudo ln -s ../sites-available/insight ./sudo ln -s ../sites-available/bws ./ 然后重启nginx： 1sudo /usr/sbin/nginx -s reload 项目的各个配置文件实际上不用改，因为用的都是 localhost ，这样的话直接运行节点，看看能不能正常访问： 这样就说说明配置正确了，bws的话基本也没问题了，运行 copay 客户端看看是不是能正常使用了，记得搜索项目中所有带有 bws/api 的uri，都换成自己的好了。 完成如果配置全都正确现在iOS客户端应该已经可以正常使用了]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>nginx</tag>
        <tag>ssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建比特币核心运行环境]]></title>
    <url>%2F2017%2F09%2F09%2F%E6%90%AD%E5%BB%BA%E6%AF%94%E7%89%B9%E5%B8%81%E6%A0%B8%E5%BF%83%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[非常感谢社区的帮助，我们已经在创造山寨币的过程中有所进展。鉴于目前的搭建教程年代比较久远，我将在这里重新整理和总结，方便对区块链技术有兴趣的童鞋们快速入门。 简要说明 我们以比特币核心作为基础，创造自己的数字货币。因此需要先搭建比特币的运行环境。源码在这：1git clone https://github.com/bitcoin/bitcoin.git 当然我也把我的魔币代码分享出来，但是目前这份代码正在修改当中，仅供参考和比对： 1git clone https://github.com/Jonathan-ZHU/Mocoin.git 感谢Harrywu，我主要参考了他的csdn博客，原文在这：【比特币】自己动手制作山寨币 目前使用的版本为0.12,因为0.12以后不能通过客户端挖矿，对于新币来说非常蛋疼。如果我们以后找到方法在新版中也能挖矿的话，会及时分享出来。 目前ubuntu上的开发和搭建较为方便,所有版本都能编译通过;Mac_OS上可能会有QT版本问题，该问题在0.12版本以后才会出现;Windows上坑最多，但是确实又好多人编译成功了。我还没编译Win，以后再来补充。 截图预览安装魔币客户端 魔币钱包主界面 挖掘出的未成熟区块 查看其他同伴 魔币钱包交易记录 接收交易界面 编译环境搭建在比特币源码根目录下./doc/中包含了环境搭建的完整过程,我就不赘述了：build-unix.md build-osx.md build-windows.md 以ubuntu为例 首先，你必须确保每一步环境的下载和安装都是正确的，安装最后如果报错了要及时想办法解决再做下一步。 Mac上用homebrew安装，复制命令进去以后，吃饭睡觉看电视，一个钟头以后回来就搭建好了;ubuntu上一句一句输入，基本网速快的话一个钟头也能搞定;Windows的话，….看你的造化了。 编译需要顺序这些命令： 1234$ ./autogen.sh$ ./configure$ make$ make install # optional configure可以带上一些参数： 12$ ./configure -with-gui --enable-debug #会编译QT客户端项目，就是我截图展示的内容$ ./configure -without-gui #要是QT环境不对，想要只编译命令行形式的客户端，可以用这个 make命令也有几个常用参数,最好加sudo，因为有些权限问题： 123$ make -B #全部重新编译$ make clean #清除编译的内容$ make -j 4 #编译过程时间长，电脑是4核的话这样写 如果你make以后没报错，恭喜你，可以打开客户端了。 文件目录结构有几点是你需要知道的：./src/为整个比特币核心的代码，由C++编写;./src/bitcoind为比特币核心启动程序;./src/bitcoin-cli为客户端控制程序，命令行中会用到;./qt/为qt项目目录，qt的客户端其实就是调用了bitcoind和bitcoin-cli的接口。 安装目录（包含输出日志、区块链等等）默认在其他目录下：Linux在～/.bitcoin中;Mac在/User/YOURNAME/Library/Application Support/Bitcoin中，不太好找，用前往或者终端;windows在C盘下的Bitcoin。如果想在代码里改改默认路径可以去./src/utils.h第455行左右，找GetDefaultDataDir函数。 可用命令行跟踪日志文件，日志文件在上面说的bitcoin文件夹里面（mac上直接点开文件就行）：1$ tail -f debug.log qt 客户端调试 打开qt的IDE New Project -&gt; Import Project -&gt; 导入现有项目，选择src/qt文件夹 点最左边竖排上的项目，点右边的管理构建套件，英文好像是什么什么kits;选桌面（默认）-&gt;然后看截图吧，这么选就行： 然后就点击调试吧，让你选启动文件你就选那个bitcoin-qt就行。 Done～命令行启动 两种启动方式中能同时启动一种哦～ 命令行启动客户端： 1234$ ./src/bitcoind$ ./src/bitcoind -daemon #后台启动，一般都要加，然后在debug.log里看输出就行$ ./src/bitcoind -gen=1 #自动挖矿$ ./src/bitcoind help #其他的自己看去吧 操作客户端： 1234$ ./src/bitcoin-cli stop$ ./src/bitcoin-cli getinfo #查看当前信息$ ./src/bitcoin-cli getpeerinfo #查看其他节点$ ./src/bitcoin-cli help #其他的自己看去吧 到此为止，能编译好运行就可以自己体验下了。 好了，先写到这下一篇我也会尽快发，会详细讲解如何调整比特币源码来创造自己的货币。欢迎来我们的博客http://www.tiny-calf.com]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>比特币</tag>
        <tag>BitcoinCore</tag>
        <tag>比特币核心</tag>
        <tag>Bitcoin</tag>
        <tag>blockhain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 发布 bitcoin-qt]]></title>
    <url>%2F2017%2F09%2F04%2FBitcoinCore%E5%8F%91%E5%B8%83Windows%E5%AE%89%E8%A3%85%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[本篇简单记录一下使用交叉编译发布Windows安装程序的方法 版本和环境目前我在以下环境编译没有出现任何问题： Windows 10 64位 （推荐使用64位） Ubuntu 14.04.5 desktop amd64 虚拟机（14版ubuntu编译windows是最不容易出现问题的） Bitcoin Core v0.14.0(旧版本在出了linux的平台上发布问题比较多，因此这里用了比较新的版本) 交叉编译Unix环境搭建首先按照doc/build_unix.md中的指示吧Unix的编译流程搭建好，这里不再多介绍了 交叉编译环境搭建安装所需环境：1sudo apt-get install build-essential libtool autotools-dev automake pkg-config bsdmainutils curl 安装64位下的环境：1sudo apt-get install g++-mingw-w64-x86-64 mingw-w64-x86-64-dev 使用命令编译：123456cd dependsmake HOST=x86_64-w64-mingw32cd .../autogen.sh # not required when building from tarballCONFIG_SITE=$PWD/depends/x86_64-w64-mingw32/share/config.site ./configure --prefix=/make 如果你是32位：1sudo apt-get install g++-mingw-w64-i686 mingw-w64-i686-dev 使用命令编译：123456cd dependsmake HOST=i686-w64-mingw32cd .../autogen.sh # not required when building from tarballCONFIG_SITE=$PWD/depends/i686-w64-mingw32/share/config.site ./configure --prefix=/make 发布安装程序1make install DESTDIR=/mnt/c/workspace/bitcoin 截图]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>比特币</tag>
        <tag>BitcoinCore</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建轻量级数字货币钱包]]></title>
    <url>%2F2017%2F08%2F09%2F%E6%90%AD%E5%BB%BAbws%E5%92%8Ccopay%2F</url>
    <content type="text"><![CDATA[本节我们在bitcore的基础上搭建我们自己货币的BWS（bitcore-wallet-service,比特核心钱包服务）以及依赖该服务的钱包客户端copay 准备条件确保你已经成功编译和运行了 bitcoin core 正如我最早的几篇教程所讲，另外确保你已经成功搭建 bitcore 和区块链浏览器 insight ，因为我是接着那一篇来讲的，没有的话看这里：创造数字货币（4）– 搭建区块链浏览器 安装 BWS之前我讲过用 nohup 启动守护进程，如果你也这么做了，那就先关闭正在运行的 bitcored 1killall bitcored BWS 使用 mongodb 作为数据库，安装 mongodb 1sudo apt-get install mongodb 安装完成以后会自动启动 mongdb 可以用命令$ mongo试一下能不能进入mongo的shell界面： 12345678910$ mongoMongoDB shell version: 2.6.10connecting to: testWelcome to the MongoDB shell.For interactive help, type "help".For more comprehensive documentation, see http://docs.mongodb.org/Questions? Try the support group http://groups.google.com/group/mongodb-user&gt; 可以的话就 exit。然后 BWS 可以单独安装，但是我们既然做了节点，那么就可以用 bitcore 安装：12cd yournodebitcore install bitcore-wallet-service 修改以下bws的配置文件，在节点目录下的这个位置： 1./node_modules/bitcore-wallet-service/config.js 可以按照自己的改，但是如果你是按照我的教程做的话，只要改一个地方： 12345678910111213blockchainExplorerOpts: &#123; livenet: &#123; provider: 'insight', url: 'https://insight.bitpay.com:443', &#125;, testnet: &#123; provider: 'insight', url: 'https://test-insight.bitpay.com:443', // url: 'http://localhost:3001', // Multiple servers (in priority order) // url: ['http://a.b.c', 'https://test-insight.bitpay.com:443'], &#125;,分支 &#125;, 把这里面的url统统换成你自己的insight地址，服务器地址或者localhost： 1234567891011121314blockchainExplorerOpts: &#123; livenet: &#123; provider: 'insight', url: 'http://localhost:3001/insight', &#125;, testnet: &#123; provider: 'insight', url: 'http://localhost:3001/insight', // url: 'http://localhost:3001', // Multiple servers (in priority order) // url: ['http://a.b.c', 'https://test-insight.bitpay.com:443'], &#125; ...&#125; 保存退出，回到节点根目录，启动bitcored，然后bws的调试信息也会一块儿输出，很好区分，bitcore的输出是带时间信息的，bws的输出则没有时间信息。你可以看到bws有这些信息： 123456info Using message broker server at http://localhost:3380info Using locker server:localhost:3231ERR! Error connecting to Insight (livenet) @ http://localhost:3001Connection established to mongoDBinfo Limiting wallet creation per IP: 20 req/hinfo Using locker server:localhost:3231 一开始会提示ERR！，这只是因为bws和bitcored是同时启动的，过几秒就会反馈链接成功的信息： 12info Connected to Insight (testnet) @ https://test-insight.bitpay.com:443info New livenet block: 000002a3846afeaba0f9fe8b8cbbb1708c1a6059c0aa991830384edcb8c6b1e9 看到这里基本上就安装成功了，但是具体有没有安装成功我们还是得搭建好copay客户端来验证一下 搭建 copaycopay支持所有平台的客户端，包括android/iOS/MacOS/Win/Web等，非常值得我们开发和研究，git地址在这，可以可上他们关网看看：https://github.com/bitpay/copaygithub上关于安装讲的比较详细，我这只挑关键步骤，然后主要讲怎么连到我们的山寨币上 运行原版客户端在又nodejs的情况下，两句命令就能直接在web上查看copay客户端：12npm run apply:copaynpm start 运行成功了就关掉做下一步 修改api地址我们刚才搭建了bws，所以我们要把api往bws上面换，bws默认接口是 http://localhost:3232/bws/api所以我们换成这个就行，怎么换呢，改这个文件：1/home/jonathan/copay/src/js/services/configService.js 内容是这样的12345678910111213141516171819202122232425bws: &#123; url: 'https://bitpay.com/bws/api', &#125;, download: &#123; bitpay: &#123; url: 'https://bitpay.com/wallet' &#125;, copay: &#123; url: 'https://copay.io/#download' &#125; &#125;, rateApp: &#123; bitpay: &#123; ios: 'http://itunes.apple.com/WebObjects/MZStore.woa/wa/viewContentsUserReviews?id=1149581638&amp;pageNumber=0&amp;sortOrdering=2&amp;type=Purple+Software&amp;mt=8', android: 'https://play.google.com/store/apps/details?id=com.bitpay.wallet', wp: '' &#125;, copay: &#123; ios: 'http://itunes.apple.com/WebObjects/MZStore.woa/wa/viewContentsUserReviews?id=951330296&amp;pageNumber=0&amp;sortOrdering=2&amp;type=Purple+Software&amp;mt=8', android: 'https://play.google.com/store/apps/details?id=com.bitpay.copay', wp: '' &#125; &#125;, 把最上面那个url换成我们搭建好的bws的接口地址，如果要做成产品其他地址也得换，你们看着办就行。第一个url最重要，关系到能不能调通钱包。改好以后保存退出，做下一步。 修改网络参数和上一篇一样，copay里面也有bitcore-lib模块，我们需要修改networks.js中的addNekwork参数，参照上一篇就行。networks.js的地址在copay的这里： 1./node_modules/bitcore-wallet-client/node_modules/bitcore-lib/lib/networks.js 注意：修改api时候那个文件configService.js，能通过git保存，但是networks.js在node模块中，是安装的时候下载的，没法通过git同步，这里建议把network.js考出来做的脚本，在别的地方安装的时候直接复制进去即可 运行测试用之前的方式启动copay，在浏览器中获取地址，从你搭建好的钱包打点钱过来，如果能打过来，就表示成功了！ TODO 修改界面 修改各种url链接（可别连到别人那去）]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>比特币</tag>
        <tag>BWS</tag>
        <tag>copay</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git取消跟踪已追踪的文件]]></title>
    <url>%2F2017%2F08%2F07%2FGit%E5%8F%96%E6%B6%88%E8%B7%9F%E8%B8%AA%E5%B7%B2%E8%BF%BD%E8%B8%AA%E7%9A%84%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Git 是一个很好的版本控制工具，当然驾驭起来相比 SVN 要稍微复杂一些。初入 Git，难免有一些问题。比如我们不小心将某个文件加入了版本控制，但是突然又不想继续跟踪控制这个文件了，怎么办呢？ 其实方法也是很简单的。使用git update-index 即可。 不想继续追踪某个文件1git update-index --assume-unchanged your_file_path 如果想再次继续跟踪某个文件1git update-index --no-assume-unchanged your_file_path]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Ubuntu上配置iptables]]></title>
    <url>%2F2017%2F08%2F04%2F%E5%9C%A8Ubuntu%E4%B8%8A%E9%85%8D%E7%BD%AEiptables%2F</url>
    <content type="text"><![CDATA[列出当前规则Ubuntu服务器默认不执行任何限制，但是为了将来参考，请使用以下命令检查当前的iptable规则1sudo iptables -L 添加规则比如允许8888端口的访问：1sudo iptables -A INPUT -p tcp -m tcp --dport 8888 -j ACCEPT 保存和恢复规则现在，如果要重新启动云服务器，那么所有这些iptables配置将被擦除。为了防止这种情况，请将规则保存到文件中1sudo iptables-save&gt; /etc/iptables/rules.v4 然后，您可以通过阅读保存的文件来简单地还原保存的规则1234＃覆盖当前规则sudo iptables-restore &lt;/etc/iptables/rules.v4＃添加新的规则保留当前的规则sudo iptables-restore -n &lt;/etc/iptables/rules.v4 您可以在重新启动时自动执行恢复过程，方法是安装iptables的附加软件包，以接管已保存的规则的加载。使用以下命令给它1sudo apt-get install iptables-persistent 安装完成后，初始设置将要求保存IPv4和IPv6的当前规则，只需选择是并按两次。 如果您进一步更改iptables规则，请记住使用与上述相同的命令再次保存它们。iptables持久性在/ etc / iptables下查找文件rules.v4和rules.v6。 这些只是您可以使用iptables的几个简单命令，它能够提供更多的功能。请阅读以检查可用于更高级控制iptable规则的其他一些选项。 #参考地址https://www.upcloud.com/support/configuring-iptables-on-ubuntu-14-04/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建区块链浏览器 insight]]></title>
    <url>%2F2017%2F07%2F20%2F%E6%90%AD%E5%BB%BA%E5%8C%BA%E5%9D%97%E9%93%BE%E6%B5%8F%E8%A7%88%E5%99%A8%2F</url>
    <content type="text"><![CDATA[bitcore 是搭建区块链浏览器 insight 和半中心化钱包 copay 的核心;由于 bitcore 完全基于 bitcoin core 所编译的二进制程序 bitcoind ，所以我们完全可以用我们已经开发的山寨币来作为bitcore的基础，开发我们自己的区块链浏览器和钱包 了解bitcorebitcore 的官网，包括了介绍、论坛、文档，我这就不多介绍了，我后面主要讲怎么把我们的山寨币用在bitcore上：https://bitcore.io/讲简单点，各个模块的关系就是：bitcoind -&gt; bitcore-&gt; insight-ui(区块链浏览器)和insight-api（区块链接口）-&gt; bws(bitcore-wallet-service) -&gt; copay和bitcore-wallet钱包;后者基于前者之上。关于bws和copay我们下节会讲。 截图预览 运行 bitcore 及 insight重编译 Bitcoind我前几章就是bitcoin core的编译教程，并且在此基础上通过修改部分参数创造了新币。但是现在我们要做一些调整，让bitcoind程序适应bitcore。方法很简单，用bitcore官方提供的bitcoin core编译就行了，代码和我们之前开发的v0.12几乎没变化，只是多了几个可供bitcore调用的RPC接口，和我们改动的部分没说明关系。这样的话我们直接把参数换到新的工程里就好了，我们接下来要编译的整套工程会基于v0.12.1-bitbore-4这个版本，在这里下载（千万别下别的版本）：https://github.com/Jonathan-ZHU/bitcoin/tree/v0.12.1-bitcore-4调整的文件也就是那几个，大概是：chainparams.cpp/chainparamsseed.h/consensus.h 等等，根据自己的来就行，重新编译好我们把 bitcoind 拿出来，按照我写过的教程做个unix发布程序就行，别忘了把bitcoin-cli也放进去，不然不小心打开了都关不掉，然后直接放到linux服务器上安装。如果还是缺少zmq库的话就再装一下呗～：1sudo apt-get install libzmq3-dev build-essential ==注意：bitcoind编译的时候，zmq环境是选装的，但是要使用bitcore，zmq是必装的，没装的滚回去装吧～==另外，本地调试也是没问题的,看着办吧 安装Node.js我单独写过nvm快速安装教程，传送门。 安装bitcore全局安装bitcore1npm install -g bitcore 然后执行看看能不能运行：1bitcored 你是不会成功的！！！没错，这就是bitcore留下的一个大坑，报错如下： 123throw new Error(message); ^Error: More than one instance of bitcore-lib found. Please make sure to require bitcore-lib and check that submodules do not also include their own bitcore-lib dependency. 原因是bitcore的各个子模块也带着bitcore-lib，当然没关系，由于node模块是自动搜索的，本地没有会往上一层搜索，上一层没有就会找全局的，所以其实我们删掉重复的模块就行了，先找到bitcore全局安装的位置，刚才的报错信息里面有，由于我们之前安装了nvm所以地址大概是这样的：1/home/ubuntu/.nvm/versions/node/v4.8.4/lib/node_modules/bitcore 这个地址有点长，做个链接吧,地址根据自己的来哦：1$ ln -s ~/.nvm/versions/node/v4.8.4/lib/node_modules/bitcore ~/bitcore 进入这个目录以后,查到所有bitcore-lib：1234$ find . -name "bitcore-lib"./node_modules/bitcore-node/node_modules/bitcore-lib./node_modules/bitcore-lib./node_modules/insight-api/node_modules/bitcore-lib 除了根目录的都删除：12rm -r ./node_modules/bitcore-node/node_modules/bitcore-librm -r ./node_modules/insight-api/node_modules/bitcore-lib 确定自己的bitcoin程序是关闭的以后，启动bitcored，由于全局安装bitcore的时候把insight-api和insight-ui都装上了，所以现在可以直接查看区块连浏览器1http://YOUR_IP_ADDRESS_OR_LOCALHOST:3001/insight/ 现在运行在比特币上，用的是npm安装时候下载的bitcoind，数据文件在～/.bitcore/ 下,如果通了就关掉把，然后接下来你有两条路可以走：一个是直接在现在的bitcore下面开发，但是以后安装bws会遇到各种版本不兼容问题，需要自己来调试;第二种是通过已有的bitcore生成一个节点，在节点上开发，强烈推荐这种，这也是我接下来要讲的，他能直接安装对应版本的bws，并且引用的库相对简洁，容易开发。 安装 bitcore full node很高兴你选择了正确的道路，让我们继续,在你想要的目录下创建新节点：1bitcore create NAME_OF_YOURNODE cd以下这个目录，再运行1bitcored 不报错，能运行的话就关掉，继续安装insight-ui和insight-api1bitcore install insight-api insight-ui 然后再运行bitcored，然后老问题又来了，bitcore-lib重复了，根刚才一样删除掉就行，运行成功以后打开，再在浏览器里看看能不能运行成功，成功的话就恭喜你，bitcore和insight已经成功安装，接下来我们就要让bitcore运行我们自己的山寨币了。 接入自己的山寨币修改bitcore-node.json就在节点根目录下，打开这个文件，是这样的：123456789101112131415161718&#123; "network": "livenet", "port": 3001, "services": [ "bitcoind", "insight-api", "insight-ui", "web" ], "servicesConfig": &#123; "bitcoind": &#123; "spawn": &#123; "datadir": "./data", "exec": "/home/ubuntu/.nvm/versions/node/v4.8.4/lib/node_modules/bitcore/node_modules/bitcore-node/bin/bitcoind" &#125; &#125; &#125;&#125; 这里面配置了网络、接口、bitcoind地址、数据地址，这些你们都看得懂，所以既然要运行在我们的山寨币上，把exec换成我们刚才安装自己的bitcoind的地址就可以了，数据地址不变也挺好，因为我们刚才启动过比特币，所以我们进入./data把刚才下载的区块链删掉，以免冲突。12$ rm -r blocks$ rm -r chainstate 查看bitcoin.conf这个文件不用改，只需要了解一下，在data里面，用来配置bitcoind启动时的各项参数。 修改networks.js现在还不要急着打开，因为网络参数还没有改，要改成我们山寨币的。文件位置在这：1./node_modules/bitcore-lib/lib/networks.js 找到这串代码：12345678910111213141516171819addNetwork(&#123; name: 'livenet', alias: 'mainnet', pubkeyhash: 0x00, privatekey: 0x80, scripthash: 0x05, xpubkey: 0x0488b21e, xprivkey: 0x0488ade4, networkMagic: 0xf9beb4d9, port: 8333, dnsSeeds: [ 'seed.bitcoin.sipa.be', 'dnsseed.bluematt.me', 'dnsseed.bitcoin.dashjr.org', 'seed.bitcoinstats.com', 'seed.bitnodes.io', 'bitseed.xf2.org' ]&#125;); 把你之前定义在bitcoin core中的参数对应过来改一下，==需要注意的是这里的pubkeyhash等等，是用16进制的==，千万别搞错，要用10进制的话把0x删掉，劳资就因为这个问题搞了一整天才发现。 Finally没什么问题的话在节点根目录执行bitcored打开吧，你已经有自己的区块链浏览器了嘿～然后我们下一章将怎么接入copay钱包，那样的话你将拥有android/iOS/MacOS/Win等所有平台的钱包客户端。 守护进程呢？特么我也不知道，官网的文档根本就不对，先用nohup代替一下把，反正也挺好用的: 12$ cd yournode$ nohup bitcored &amp; 补充RPC端口如果你的山寨币改过RPC端口的话，需要在启动 bitcoind 的配置文件 bitcoin.conf 里重新写上 1rpcport=99999 虽然 bitcoind 在运行的时候会找到默认端口，但是 insight-api 会搜索该配置文件，如果没有设置的话默认还是8332]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>比特币</tag>
        <tag>insight</tag>
        <tag>bitcore</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nodejs快速安装]]></title>
    <url>%2F2017%2F07%2F20%2FNode.js%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[用安装包上传安装实在太慢了 而且多个版本的node也没法发控制 我们使用nvm工具会快的多 假设环境设定 ubuntu v16.04 没有安装npm和node 安装 npm1$ apt install npm 安装 nvm找 nvm git 库点我 里面也有安装说明执行：1$ wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash 再执行：12export NVM_DIR="$HOME/.nvm"[ -s "$NVM_DIR/nvm.sh" ] &amp;&amp; . "$NVM_DIR/nvm.sh" 输入 nvm 看看有没有正确安装 安装nodejs假设我们要装 v4版本的node：1$ nvm install v4.* 如果还装过别的版本则执行一下来切换版本：1$ nvm use 4 OK，安装好了，快吧～]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>nvm</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux创建新用户]]></title>
    <url>%2F2017%2F07%2F15%2FLinux%E5%88%9B%E5%BB%BA%E6%96%B0%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[创建用户 1$ useradd -r -m YOURNAME 设置密码 一定要用这种形式，接着输入一下密码，不然会显示密码无效 12&lt;!-- more --&gt;$ passwd YOURNAME 结果是这样的1234$ sudo passwd YOURNAMEEnter new UNIX password:Retype new UNIX password:passwd: password updated successfully 用新用户登录1$ sudo su - YOURNAME 然后试试sudo命令，发现不能用：12[sudo] password for YOURNAME:YOURNAME is not in the sudoers file. This incident will be reported. 不要紧我们先 exit 回到root，执行：1$ sudo usermod -a -G sudo YOURNAME 注意：千万不要学网上找的教程说要改 /etc/sudoers注意：千万不要学网上找的教程说要改 /etc/sudoers注意：千万不要学网上找的教程说要改 /etc/sudoers 最后测试以下新用户的 sudo 即可]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>
